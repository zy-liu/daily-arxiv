<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems](https://arxiv.org/abs/2506.22648)
*Pedro R. Pires,Tiago A. Almeida*

Main category: cs.IR

TL;DR: 本文提出了Interact2Vec，一种新的基于神经网络的推荐模型，能够同时学习用户和项目的分布式嵌入，只需要隐式反馈，并使用了自然语言处理中的先进策略来优化训练和提升嵌入质量。


<details>
  <summary>Details</summary>
Motivation: 推荐系统面临着数据高维度和稀疏性的挑战，低维嵌入技术被用作解决方案，但现有的许多方法依赖于复杂架构或内容数据，可能无法始终获得。

Method: Interact2Vec模型使用神经网络学习用户和项目的分布式嵌入，只需要隐式反馈，并采用自然语言处理中常见的策略优化训练和提升最终嵌入。

Result: 在extrinsic质量实验中，Interact2Vec在30%的数据集上表现优异，与其他推荐算法相比，平均训练时间减少了274%。在intrinsic质量实验中，通过相似度表格分析表明，Interact2Vec在extrinsic任务上能够取得良好的结果。

Conclusion: Interact2Vec能够有效地学习用户和项目嵌入，尤其在计算资源稀缺的情况下表现优异，是一种高效的嵌入生成模型。

Abstract: Over the past decade, recommender systems have experienced a surge in
popularity. Despite notable progress, they grapple with challenging issues,
such as high data dimensionality and sparseness. Representing users and items
as low-dimensional embeddings learned via neural networks has become a leading
solution. However, while recent studies show promising results, many approaches
rely on complex architectures or require content data, which may not always be
available. This paper presents Interact2Vec, a novel neural network-based model
that simultaneously learns distributed embeddings for users and items while
demanding only implicit feedback. The model employs state-of-the-art strategies
that natural language processing models commonly use to optimize the training
phase and enhance the final embeddings. Two types of experiments were conducted
regarding the extrinsic and intrinsic quality of the model. In the former, we
benchmarked the recommendations generated by Interact2Vec's embeddings in a
top-$N$ ranking problem, comparing them with six other recommender algorithms.
The model achieved the second or third-best results in 30\% of the datasets,
being competitive with other recommenders, and has proven to be very efficient
with an average training time reduction of 274\% compared to other
embedding-based models. Later, we analyzed the intrinsic quality of the
embeddings through similarity tables. Our findings suggest that Interact2Vec
can achieve promising results, especially on the extrinsic task, and is an
excellent embedding-generator model for scenarios of scarce computing
resources, enabling the learning of item and user embeddings simultaneously and
efficiently.

</details>


### [2] [Machine Assistant with Reliable Knowledge: Enhancing Student Learning via RAG-based Retrieval](https://arxiv.org/abs/2506.23026)
*Yongsheng Lian*

Main category: cs.IR

TL;DR: 本文介绍了MARK，一个通过可靠知识增强的问答系统，用于支持学生的学习。


<details>
  <summary>Details</summary>
Motivation: 提出MARK系统，旨在通过准确且有上下文根据的回答来支持学生的学习。

Method: MARK基于检索增强生成(RAG)框架，整合了经过筛选的知识库以确保事实一致性。采用混合搜索策略，结合密集向量相似性和稀疏关键词检索，增强检索有效性。

Result: 系统部署在教室环境中，成功处理了广泛的学生查询，并展现出处理特定领域任务的能力。

Conclusion: MARK系统能够适应性地改进，有效支持学生学习和提供技术支持，是传统办公室小时的良好替代方案。

Abstract: We present Machine Assistant with Reliable Knowledge (MARK), a
retrieval-augmented question-answering system designed to support student
learning through accurate and contextually grounded responses. The system is
built on a retrieval-augmented generation (RAG) framework, which integrates a
curated knowledge base to ensure factual consistency. To enhance retrieval
effectiveness across diverse question types, we implement a hybrid search
strategy that combines dense vector similarity with sparse keyword-based
retrieval. This dual-retrieval mechanism improves robustness for both general
and domain-specific queries. The system includes a feedback loop in which
students can rate responses and instructors can review and revise them.
Instructor corrections are incorporated into the retrieval corpus, enabling
adaptive refinement over time. The system was deployed in a classroom setting
as a substitute for traditional office hours, where it successfully addressed a
broad range of student queries. It was also used to provide technical support
by integrating with a customer-specific knowledge base, demonstrating its
ability to handle routine, context-sensitive tasks in applied domains. MARK is
publicly accessible at https://app.eduquery.ai.

</details>


### [3] [Synergizing Implicit and Explicit User Interests: A Multi-Embedding Retrieval Framework at Pinterest](https://arxiv.org/abs/2506.23060)
*Zhibo Fan,Hongtao Lin,Haoyu Chen,Bowen Deng,Hedi Xia,Yuke Yan,James Li*

Main category: cs.IR

TL;DR: 本文提出一个多嵌入检索框架以增强用户兴趣表示，通过差异化聚类模块（DCM）捕捉隐式兴趣，并通过条件检索（CR）处理明确兴趣（如用户订阅的主题），从而提高候选物品检索的有效性和全面性。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统中，检索阶段面临挑战，特别是传统双塔模型难以有效覆盖多样化和长尾用户兴趣，本文旨在解决这一问题。

Method: 提出一个创新的多嵌入检索框架，通过结合差异化聚类模块（DCM）和条件检索（CR）的隐式和显式用户兴趣表示，增强用户兴趣的建模。

Result: 通过实验和A/B测试获得显著的用户参与度提升和内容多样性改进。

Conclusion: 该框架已在Pinterest主信息流中得到成功部署，显示出该框架提高推荐系统的有效性和用户满意度的能力。

Abstract: Industrial recommendation systems are typically composed of multiple stages,
including retrieval, ranking, and blending. The retrieval stage plays a
critical role in generating a high-recall set of candidate items that covers a
wide range of diverse user interests. Effectively covering the diverse and
long-tail user interests within this stage poses a significant challenge:
traditional two-tower models struggle in this regard due to limited user-item
feature interaction and often bias towards top use cases. To address these
issues, we propose a novel multi-embedding retrieval framework designed to
enhance user interest representation by generating multiple user embeddings
conditioned on both implicit and explicit user interests. Implicit interests
are captured from user history through a Differentiable Clustering Module
(DCM), whereas explicit interests, such as topics that the user has followed,
are modeled via Conditional Retrieval (CR). These methodologies represent a
form of conditioned user representation learning that involves condition
representation construction and associating the target item with the relevant
conditions. Synergizing implicit and explicit user interests serves as a
complementary approach to achieve more effective and comprehensive candidate
retrieval as they benefit on different user segments and extract conditions
from different but supplementary sources. Extensive experiments and A/B testing
reveal significant improvements in user engagements and feed diversity metrics.
Our proposed framework has been successfully deployed on Pinterest home feed.

</details>


### [4] [Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences](https://arxiv.org/abs/2506.23085)
*Saeid Aghasoleymani Najafabadi*

Main category: cs.IR

TL;DR: 本文提出一种融合用户偏好、交互数据、视频内容特征和上下文信息的多模态推荐系统，运用了多模态图卷积网络MMGCN以及协同过滤和基于内容的过滤技术，旨在提高直播互动性，并分别在Kwai、TikTok和MovieLens数据集上优于传统推荐模型。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探索通过开发一个包括多模态图卷积网络（MMGCN）和用户偏好的短视频推荐系统来增强直播互动性。

Method: 本文提出的方法是采用融合多模态数据（包括用户交互数据、视频内容特征和上下文信息）的方法，结合协同过滤和基于内容的过滤技术来生成推荐。

Result: 评价系统有效性的结果显示，相比于DeepFM、Wide & Deep、LightGBM和XGBoost等基线模型，MMGCN模型在Kwai F1得分0.574、TikTok F1得分0.506和MovieLens F1得分0.197上均表现更优。

Conclusion: 本文强调多模态集成和以用户为中心的方法在推进推荐系统中的重要性，特别是在增强内容发现和观众在直播平台上的互动方面。

Abstract: The purpose of this paper is to explore a multi-modal approach to enhancing
live broadcast engagement by developing a short video recommendation system
that incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user
preferences. In order to provide personalized recommendations tailored to
individual interests, the proposed system takes into account user interaction
data, video content features, and contextual information. With the aid of a
hybrid approach combining collaborative filtering and content-based filtering
techniques, the system is able to capture nuanced relationships between users,
video attributes, and engagement patterns. Three datasets are used to evaluate
the effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to
baseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the
proposed MMGCN-based model shows superior performance. A notable feature of the
proposed model is that it outperforms all baseline methods in capturing diverse
user preferences and making accurate, personalized recommendations, resulting
in a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1
score of 0.197. We emphasize the importance of multi-modal integration and
user-centric approaches in advancing recommender systems, emphasizing the role
they play in enhancing content discovery and audience interaction on live
broadcast platforms.

</details>


### [5] [Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems](https://arxiv.org/abs/2506.23090)
*Langming Liu,Wanyu Wang,Chi Zhang,Bo Li,Hongzhi Yin,Xuetao Wei,Wenbo Su,Bo Zheng,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 本文提出了一种称为MTORL的新型多任务离线强化学习模型，旨在解决推荐平台在线广告中的预算分配和渠道推荐问题，特别是在稀疏广告场景下遇到的过度估计、分布偏移和预算约束等挑战。


<details>
  <summary>Details</summary>
Motivation: 由于目前的离线强化学习方法在处理稀疏广告场景时面临过度估计、分布偏移和忽略预算约束等难题，文章提出了新的方法来改善这些问题。

Method: 文章建立了一个特定于广告的马尔可夫决策过程（MDP）框架，并开发了一种因果状态编码器来捕捉用户的动态兴趣和时序依赖性。为此使用了因果注意力机制来增强用户序列表示，同时采用多任务学习来解码动作和奖励。

Result: 在离线和在线环境中的大量实验表明，MTORL在效率上优于当前最先进的方法。

Conclusion: MTORL模型有效地解决了在线广告中的推荐和预算分配问题，特别是在处理稀疏广告数据和预算限制方面的挑战，代表了处理此类问题的一个进步。

Abstract: Online advertising in recommendation platforms has gained significant
attention, with a predominant focus on channel recommendation and budget
allocation strategies. However, current offline reinforcement learning (RL)
methods face substantial challenges when applied to sparse advertising
scenarios, primarily due to severe overestimation, distributional shifts, and
overlooking budget constraints. To address these issues, we propose MTORL, a
novel multi-task offline RL model that targets two key objectives. First, we
establish a Markov Decision Process (MDP) framework specific to the nuances of
advertising. Then, we develop a causal state encoder to capture dynamic user
interests and temporal dependencies, facilitating offline RL through
conditional sequence modeling. Causal attention mechanisms are introduced to
enhance user sequence representations by identifying correlations among causal
states. We employ multi-task learning to decode actions and rewards,
simultaneously addressing channel recommendation and budget allocation.
Notably, our framework includes an automated system for integrating these tasks
into online advertising. Extensive experiments on offline and online
environments demonstrate MTORL's superiority over state-of-the-art methods.

</details>


### [6] [Compositions of Variant Experts for Integrating Short-Term and Long-Term Preferences](https://arxiv.org/abs/2506.23170)
*Jaime Hieu Do,Trung-Hoang Le,Hady W. Lauw*

Main category: cs.IR

TL;DR: 这篇论文提出了一个名为CoVE的推荐系统框架，它能结合短期和长期用户偏好，从而提高推荐效果。


<details>
  <summary>Details</summary>
Motivation: 在在线数字领域中，推荐系统对于改善用户体验发挥着至关重要的作用，这篇论文探讨了如何通过考虑用户累积的历史行为和即时会话上下文来提供相关及时的推荐。

Method: 基于对不同真实世界数据集的实证研究，分析了短期和长期偏好的存在及其对用户历史交互的影响，进而提出了一个结合短期和长期偏好的推荐框架。

Result: 实验表明，所提出的方法非常有效，磨除研究更进一步研究了不同类型专家的影响。

Conclusion: 通过使用不同的专业推荐模型（专家），该框架能够动态地整合短期和长期偏好，显著地提升推荐性能。

Abstract: In the online digital realm, recommendation systems are ubiquitous and play a
crucial role in enhancing user experience. These systems leverage user
preferences to provide personalized recommendations, thereby helping users
navigate through the paradox of choice. This work focuses on personalized
sequential recommendation, where the system considers not only a user's
immediate, evolving session context, but also their cumulative historical
behavior to provide highly relevant and timely recommendations. Through an
empirical study conducted on diverse real-world datasets, we have observed and
quantified the existence and impact of both short-term (immediate and
transient) and long-term (enduring and stable) preferences on users' historical
interactions. Building on these insights, we propose a framework that combines
short- and long-term preferences to enhance recommendation performance, namely
Compositions of Variant Experts (CoVE). This novel framework dynamically
integrates short- and long-term preferences through the use of different
specialized recommendation models (i.e., experts). Extensive experiments
showcase the effectiveness of the proposed methods and ablation studies further
investigate the impact of variant expert types.

</details>


### [7] [Impact of Shallow vs. Deep Relevance Judgments on BERT-based Reranking Models](https://arxiv.org/abs/2506.23191)
*Gabriel Iturra-Bocaz,Danny Vo,Petra Galuscakova*

Main category: cs.IR

TL;DR: 本论文探讨了浅层和深层相关性判断对BERT模型在神经信息检索中性能的影响。实验表明浅层数据集提高泛化性能，而深层数据集可通过增加负训练样本减轻其劣势。


<details>
  <summary>Details</summary>
Motivation: 随着神经信息检索的发展，研究不同类型的数据集对BERT模型性能的影响显得尤为重要，本论文旨在比较浅层和深层判断数据集在模型 reranking 性能上的差异。

Method: 通过在MS MARCO和LongEval数据集上运行实验，比较使用浅层和深层判断数据集训练的BERT模型在re-ranking任务中的表现。

Result: 浅层数据集通常提高reranking模型的泛化能力和效率，这可能是因为它们提供了更多的上下文范围。深层数据集的缺陷可以通过增加负训练样本的数量来弥补。

Conclusion: 浅层和深层判断数据集对BERT模型性能有不同影响，应根据需求选择合适的数据集。增加负例训练可以有效提升深层数据集训练的模型性能。

Abstract: This paper investigates the impact of shallow versus deep relevance judgments
on the performance of BERT-based reranking models in neural Information
Retrieval. Shallow-judged datasets, characterized by numerous queries each with
few relevance judgments, and deep-judged datasets, involving fewer queries with
extensive relevance judgments, are compared. The research assesses how these
datasets affect the performance of BERT-based reranking models trained on them.
The experiments are run on the MS MARCO and LongEval collections. Results
indicate that shallow-judged datasets generally enhance generalization and
effectiveness of reranking models due to a broader range of available contexts.
The disadvantage of the deep-judged datasets might be mitigated by a larger
number of negative training examples.

</details>


### [8] [Learning to Rank with Variable Result Presentation Lengths](https://arxiv.org/abs/2506.23319)
*Norman Knyazev,Harrie Oosterhuis*

Main category: cs.IR

TL;DR: 本文提出了变量呈现长度排名任务，并设计了VLPL方法来联合优化文档排序和长度，展示了相对于固定长度模型，对文档的预期曝光度和吸引力进行有效平衡。


<details>
  <summary>Details</summary>
Motivation: 现有排序方法假设每个文档的呈现格式相同，但用户对相关性的感知受文档呈现长度影响。本文针对未解决的文档呈现长度选择问题，提出新的排名任务。

Method: 提出VLPL方法，通过Plackett-Luce列表梯度估计进行文档排序和长度的联合优化。

Result: 实验表明，VLPL能有效平衡文档的预期曝光度和吸引力，在多种排名设置中表现最佳，简单长度感知方法相比固定长度模型有显著性能提升。

Conclusion: 本文的理论和实证结果强调了结合文档呈现与LTR的重要性及难度。

Abstract: Learning to Rank (LTR) methods generally assume that each document in a top-K
ranking is presented in an equal format. However, previous work has shown that
users' perceptions of relevance can be changed by varying presentations, i.e.,
allocating more vertical space to some documents to provide additional textual
or image information. Furthermore, presentation length can also redirect
attention, as users are more likely to notice longer presentations when
scrolling through results. Deciding on the document presentation lengths in a
fixed vertical space ranking is an important problem that has not been
addressed by existing LTR methods.
  We address this gap by introducing the variable presentation length ranking
task, where simultaneously the ordering of documents and their presentation
length is decided. Despite being a generalization of standard ranking, we show
that this setting brings significant new challenges: Firstly, the probability
ranking principle no longer applies to this setting, and secondly, the problem
cannot be divided into separate ordering and length selection tasks.
  We therefore propose VLPL - a new family of Plackett-Luce list-wise gradient
estimation methods for the joint optimization of document ordering and lengths.
Our semi-synthetic experiments show that VLPL can effectively balance the
expected exposure and attractiveness of all documents, achieving the best
performance across different ranking settings. Furthermore, we observe that
even simple length-aware methods can achieve significant performance
improvements over fixed-length models. Altogether, our theoretical and
empirical results highlight the importance and difficulties of combining
document presentation with LTR.

</details>


### [9] [Teaching a Language Model to Speak the Language of Tools](https://arxiv.org/abs/2506.23394)
*Simeon Emanuilov*

Main category: cs.IR

TL;DR: 该研究开发了一种方法，可通过双语数据集训练多语言模型，使其能在非英语语言中可靠地使用外部工具。


<details>
  <summary>Details</summary>
Motivation: 目前大多数多语言模型在非英语国家缺乏可靠的工具使用能力，即使是先进的模型也难以确定何时使用工具或生成必要的结构化输出。

Method: 研究者对BgGPT模型系列进行持续训练，使用了含有10,035个函数调用示例的新型双语数据集，这些示例支持标准化的MCP协议。

Result: 新模型TUCAN在保住语言理解能力的同时，实现了28.75%的函数调用准确度提升，且能生成干净、可解析的函数调用输出。

Conclusion: 该研究展示了如何使工具增强的语言模型功能摆脱英语中心化，为其他语言也提供了新的模型、评估框架和数据集，以供进一步的研究和复现。

Abstract: External tool integration through function-calling is essential for practical
language model applications, yet most multilingual models lack reliable
tool-use capabilities in non-English languages. Even state-of-the-art
multilingual models struggle with determining when to use tools and generating
the structured outputs required for function calls, often exhibiting language
confusion when prompted in lower-resource languages. This work presents a
methodology for adapting existing language models to enable robust tool use in
any target language, using Bulgarian as a case study. The approach involves
continued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a
novel bilingual dataset of 10,035 function-calling examples designed to support
standardized protocols like MCP (Model Context Protocol). The research
introduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to
28.75% improvement in function-calling accuracy over base models while
preserving core language understanding, as verified on established Bulgarian
benchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready
response formatting with clean, parsable function calls, contrasting with the
verbose and inconsistent outputs of base models. The models, evaluation
framework, and dataset are released to enable replication for other languages.
This work demonstrates a practical approach for extending tool-augmented
capabilities beyond English-centric systems.

</details>


### [10] [NaviX: A Native Vector Index Design for Graph DBMSs With Robust Predicate-Agnostic Search Performance](https://arxiv.org/abs/2506.23397)
*Gaurav Sehgal,Semih Salihoglu*

Main category: cs.IR

TL;DR: NaviX是一个为图数据库管理系统（GDBMSs）设计的原生向量索引，支持在结构化和连接属性中查询向量嵌入，并采用预处理过滤方法实现高效的向量搜索。


<details>
  <summary>Details</summary>
Motivation: 由于预测应用的需要，扩展现有的数据库管理系统以支持向量索引的需求日益增加。需要联合查询向量嵌入及其对象的属性和连接关系。

Method: NaviX是基于层次导航小世界（HNSW）图构建的磁盘向量索引，结合了下层GDBMS的核心存储和查询处理能力。另外，NaviX支持预过滤的k最近邻（kNN）搜索，通过先评估查询子查询QS定义的向量子集S，然后将完整描述传递给kNN搜索操作符。

Result: NaviX通过自适应算法根据HNSW图中每个向量的局部选择性来选择合适的启发式算法，增强了在不同选择性和不同相关性条件下的鲁棒性。

Conclusion: 实验证明，NaviX在抵抗预处理和后处理基线的鲁棒性和效率方面表现出色。

Abstract: There is an increasing demand for extending existing DBMSs with vector
indices so that they become unified systems capable of supporting modern
predictive applications, which require joint querying of vector embeddings
together with the structured properties and connections of objects. We present
NaviX, a native vector index for graph DBMSs (GDBMSs) that has two main design
goals. First, we aim to implement a disk-based vector index that leverages the
core storage and query-processing capabilities of the underlying GDBMS. To this
end, NaviX is built on the Hierarchical Navigable Small-World (HNSW) graph,
which itself is a graph-based structure. Second, we aim to support
predicate-agnostic filtered vector search queries, in which the k nearest
neighbors (kNNs) of a query vector vQ are searched only within an arbitrary
subset S of vectors defined by an ad-hoc selection sub-query QS. We adopt a
prefiltering approach that evaluates QS first and passes the full description
of subset S to the kNN search operator. We study how to design a prefiltering
search algorithm that remains robust under varying selectivities and under
different correlations between subset S and query vector vQ. We propose an
adaptive algorithm that uses the local selectivity of each vector in the HNSW
graph to choose an appropriate heuristic at every iteration of the kNN search.
Finally, We demonstrate NaviX's robustness and efficiency through extensive
experiments against both existing prefiltering- and postfiltering-based
baselines.

</details>


### [11] [KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On](https://arxiv.org/abs/2506.23471)
*Thanh-Tung Phan-Nguyen,Khoi-Nguyen Nguyen-Ngoc,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.IR

TL;DR: 这份论文提出了一个名为 KiseKloset 的综合系统，用于服装的检索、推荐和试穿，包括相似项目检索、文本反馈指导项目检索和一种新的 transformer 架构来推荐互补物品，并结合了轻量级的虚拟试穿框架，结果显示用户满意度很高。


<details>
  <summary>Details</summary>
Motivation: 提升在线购物体验，通过提供个性化推荐的购物方式。

Method: 创作了一个名为 KiseKloset 的系统，涉及服装检索、推荐和试穿技术，同时使用了相似项目检索、文本反馈指导项目检索、新的 transformer 架构和轻量级的虚拟试穿框架。

Result: 用户研究显示，84%的参与者认为该系统非常有用，大大提升了他们的在线购物体验。

Conclusion: KiseKloset 系统通过创新的策略和先进的技术显著提高了消费者的在线购物体验，展现了极大潜力改变全球时尚电子商务产业的面貌。

Abstract: The global fashion e-commerce industry has become integral to people's daily
lives, leveraging technological advancements to offer personalized shopping
experiences, primarily through recommendation systems that enhance customer
engagement through personalized suggestions. To improve customers' experience
in online shopping, we propose a novel comprehensive KiseKloset system for
outfit retrieval, recommendation, and try-on. We explore two approaches for
outfit retrieval: similar item retrieval and text feedback-guided item
retrieval. Notably, we introduce a novel transformer architecture designed to
recommend complementary items from diverse categories. Furthermore, we enhance
the overall performance of the search pipeline by integrating approximate
algorithms to optimize the search process. Additionally, addressing the crucial
needs of online shoppers, we employ a lightweight yet efficient virtual try-on
framework capable of real-time operation, memory efficiency, and maintaining
realistic outputs compared to its predecessors. This virtual try-on module
empowers users to visualize specific garments on themselves, enhancing the
customers' experience and reducing costs associated with damaged items for
retailers. We deployed our end-to-end system for online users to test and
provide feedback, enabling us to measure their satisfaction levels. The results
of our user study revealed that 84% of participants found our comprehensive
system highly useful, significantly improving their online shopping experience.

</details>


### [12] [Act-With-Think: Chunk Auto-Regressive Modeling for Generative Recommendation](https://arxiv.org/abs/2506.23643)
*Yifan Wang,Weinan Gan,Longtao Xiao,Jieming Zhu,Heng Chang,Haozhao Wang,Rui Zhang,Zhenhua Dong,Ruiming Tang,Ruixuan Li*

Main category: cs.IR

TL;DR: 本文提出了Chunk AutoRegressive Modeling (CAR)，一种通过结合内容和行为信息以提高推荐系统性能的新方法。


<details>
  <summary>Details</summary>
Motivation: 传统的生成式推荐方法通常忽略了内容和行为信息之间的内在联系，导致性能受限。

Method: CAR方法通过将内容的语义信息（SIDs）和用户行为（UID）整合到一个自回归Transformer模型中，从“行动-思考”的双重视角进行推荐。

Result: 实验结果显示，本文提出的方法在传统自回归方法的基础上有显著提升，Recall@5从7.93%提高到22.30%，并验证了模型性能与SIDs位数正相关。

Conclusion: CAR初步模仿了类似大语言模型（LLMs）中的推理过程，为推荐系统提供了新的思路和方法。

Abstract: Generative recommendation (GR) typically encodes behavioral or semantic
aspects of item information into discrete tokens, leveraging the standard
autoregressive (AR) generation paradigm to make predictions. However, existing
methods tend to overlook their intrinsic relationship, that is, the semantic
usually provides some reasonable explainability "$\textbf{why}$" for the
behavior "$\textbf{what}$", which may constrain the full potential of GR. To
this end, we present Chunk AutoRegressive Modeling (CAR), a new generation
paradigm following the decision pattern that users usually think semantic
aspects of items (e.g. brand) and then take actions on target items (e.g.
purchase). Our CAR, for the $\textit{first time}$, incorporates semantics
(SIDs) and behavior (UID) into a single autoregressive transformer from an
``act-with-think'' dual perspective via chunk-level autoregression.
Specifically, CAR packs SIDs and UID into a conceptual chunk for item unified
representation, allowing each decoding step to make a holistic prediction.
Experiments show that our CAR significantly outperforms existing methods based
on traditional AR, improving Recall@5 by 7.93% to 22.30%. Furthermore, we
verify the scaling effect between model performance and SIDs bit number,
demonstrating that CAR preliminary emulates a kind of slow-thinking style
mechanism akin to the reasoning processes observed in large language models
(LLMs).

</details>
