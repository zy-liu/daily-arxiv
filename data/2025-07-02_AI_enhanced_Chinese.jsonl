{"id": "2507.00477", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2507.00477", "abs": "https://arxiv.org/abs/2507.00477", "authors": ["Qi Wang", "Yixuan Cao", "Yifan Liu", "Jiangtao Zhao", "Ping Luo"], "title": "Read the Docs Before Rewriting: Equip Rewriter with Domain Knowledge via Continual Pre-training", "comment": null, "summary": "A Retrieval-Augmented Generation (RAG)-based question-answering (QA) system\nenhances a large language model's knowledge by retrieving relevant documents\nbased on user queries. Discrepancies between user queries and document\nphrasings often necessitate query rewriting. However, in specialized domains,\nthe rewriter model may struggle due to limited domain-specific knowledge. To\nresolve this, we propose the R\\&R (Read the doc before Rewriting) rewriter,\nwhich involves continual pre-training on professional documents, akin to how\nstudents prepare for open-book exams by reviewing textbooks. Additionally, it\ncan be combined with supervised fine-tuning for improved results. Experiments\non multiple datasets demonstrate that R\\&R excels in professional QA across\nmultiple domains, effectively bridging the query-document gap, while\nmaintaining good performance in general scenarios, thus advancing the\napplication of RAG-based QA systems in specialized fields.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faR&R\u91cd\u5199\u5668\uff0c\u901a\u8fc7\u4e13\u4e1a\u6587\u6863\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u76d1\u7763\u5fae\u8c03\u6539\u8fdb\u57fa\u4e8e\u68c0\u7d22\u7684\u751f\u6210\u5f0f\u95ee\u7b54\u7cfb\u7edf\u5728\u4e13\u4e1a\u9886\u57df\u7684\u8868\u73b0\u3002", "motivation": "\u7528\u6237\u67e5\u8be2\u548c\u6587\u6863\u8868\u8ff0\u4e4b\u95f4\u7684\u5dee\u5f02\u5bfc\u81f4\u91cd\u5199\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u4e2d\u7531\u4e8e\u77e5\u8bc6\u6709\u9650\u800c\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faR&R\u91cd\u5199\u5668\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u5728\u4e13\u4e1a\u6587\u6863\u4e0a\uff0c\u7c7b\u4f3c\u5b66\u751f\u590d\u4e60\u8bfe\u672c\u5907\u6218\u5f00\u5377\u8003\u8bd5\uff0c\u5e76\u652f\u6301\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660eR&R\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e2d\u63d0\u9ad8\u4e86\u4e13\u4e1a\u95ee\u7b54\u7cfb\u7edf\u7684\u8868\u73b0\uff0c\u6709\u6548\u7f29\u5c0f\u4e86\u67e5\u8be2\u548c\u6587\u6863\u7684\u5dee\u8ddd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u4e00\u822c\u6027\u80fd\u3002", "conclusion": "R&R\u91cd\u5199\u5668\u6539\u5584\u4e86\u57fa\u4e8e\u68c0\u7d22\u7684\u751f\u6210\u5f0f\u95ee\u7b54\u7cfb\u7edf\u5728\u4e13\u4e1a\u9886\u57df\u5e94\u7528\uff0c\u4e3a\u7279\u6b8a\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.00479", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2507.00479", "abs": "https://arxiv.org/abs/2507.00479", "authors": ["Sixiao Zhang", "Mingrui Liu", "Cheng Long", "Wei Yuan", "Hongxu Chen", "Xiangyu Zhao", "Hongzhi Yin"], "title": "On Mitigating Data Sparsity in Conversational Recommender Systems", "comment": null, "summary": "Conversational recommender systems (CRSs) capture user preference through\ntextual information in dialogues. However, they suffer from data sparsity on\ntwo fronts: the dialogue space is vast and linguistically diverse, while the\nitem space exhibits long-tail and sparse distributions. Existing methods\nstruggle with (1) generalizing to varied dialogue expressions due to\nunderutilization of rich textual cues, and (2) learning informative item\nrepresentations under severe sparsity. To address these problems, we propose a\nCRS model named DACRS. It consists of three modules, namely Dialogue\nAugmentation, Knowledge-Guided Entity Modeling, and Dialogue-Entity Matching.\nIn the Dialogue Augmentation module, we apply a two-stage augmentation pipeline\nto augment the dialogue context to enrich the data and improve\ngeneralizability. In the Knowledge-Guided Entity Modeling, we propose a\nknowledge graph (KG) based entity substitution and an entity similarity\nconstraint to enhance the expressiveness of entity embeddings. In the\nDialogue-Entity Matching module, we fuse the dialogue embedding with the\nmentioned entity embeddings through a dialogue-guided attention aggregation to\nacquire user embeddings that contain both the explicit and implicit user\npreferences. Extensive experiments on two public datasets demonstrate the\nstate-of-the-art performance of DACRS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDACRS\u7684\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u8bdd\u589e\u5f3a\u3001\u77e5\u8bc6\u5f15\u5bfc\u5b9e\u4f53\u5efa\u6a21\u548c\u5bf9\u8bdd\u5b9e\u4f53\u5339\u914d\u4e09\u4e2a\u6a21\u5757\u6765\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\u3002", "motivation": "\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff08CRSs\uff09\u5728\u6355\u6349\u7528\u6237\u504f\u597d\u65b9\u9762\u5b58\u5728\u4e24\u65b9\u9762\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\uff1a\u5bf9\u8bdd\u7a7a\u95f4\u5e9e\u5927\u4e14\u8bed\u8a00\u591a\u6837\uff1b\u9879\u76ee\u7a7a\u95f4\u8868\u73b0\u51fa\u957f\u5c3e\u548c\u7a00\u758f\u7684\u5206\u5e03\u3002", "method": "\u63d0\u51faCRS\u6a21\u578bDACRS\uff0c\u5305\u542b\u5bf9\u8bdd\u589e\u5f3a\u3001\u77e5\u8bc6\u5f15\u5bfc\u5b9e\u4f53\u5efa\u6a21\u548c\u5bf9\u8bdd\u5b9e\u4f53\u5339\u914d\u4e09\u4e2a\u6a21\u5757\u3002\u5bf9\u8bdd\u589e\u5f3a\u6a21\u5757\u4f7f\u7528\u4e24\u9636\u6bb5\u589e\u5f3a\u6d41\u7a0b\u6765\u4e30\u5bcc\u6570\u636e\u5e76\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\uff1b\u77e5\u8bc6\u5f15\u5bfc\u5b9e\u4f53\u5efa\u6a21\u6a21\u5757\u91c7\u7528\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u8fdb\u884c\u5b9e\u4f53\u66ff\u6362\u548c\u76f8\u4f3c\u6027\u7ea6\u675f\uff0c\u589e\u5f3a\u5b9e\u4f53\u5d4c\u5165\u7684\u8868\u8fbe\u80fd\u529b\uff1b\u5bf9\u8bdd\u5b9e\u4f53\u5339\u914d\u6a21\u5757\u901a\u8fc7\u5bf9\u8bdd\u5f15\u5bfc\u7684\u6ce8\u610f\u529b\u805a\u5408\u878d\u5408\u5bf9\u8bdd\u5d4c\u5165\u548c\u5b9e\u4f53\u5d4c\u5165\u83b7\u5f97\u5305\u542b\u7528\u6237\u663e\u6027\u548c\u9690\u6027\u504f\u597d\u7684\u7528\u6237\u5d4c\u5165\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660eDACRS\u8868\u73b0\u5904\u4e8e\u9876\u5c16\u6c34\u5e73\u3002", "conclusion": "DACRS\u6a21\u578b\u901a\u8fc7\u4e09\u4e2a\u521b\u65b0\u6a21\u5757\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5728\u6570\u636e\u7a00\u758f\u73af\u5883\u4e0b\u7684\u4f18\u79c0\u8868\u73b0\u3002"}}
{"id": "2507.00487", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.00487", "abs": "https://arxiv.org/abs/2507.00487", "authors": ["Jianghao Lin", "Xinyuan Wang", "Xinyi Dai", "Menghui Zhu", "Bo Chen", "Ruiming Tang", "Yong Yu", "Weinan Zhang"], "title": "MassTool: A Multi-Task Search-Based Tool Retrieval Framework for Large Language Models", "comment": null, "summary": "Tool retrieval is a critical component in enabling large language models\n(LLMs) to interact effectively with external tools. It aims to precisely filter\nthe massive tools into a small set of candidates for the downstream\ntool-augmented LLMs. However, most existing approaches primarily focus on\noptimizing tool representations, often neglecting the importance of precise\nquery comprehension. To address this gap, we introduce MassTool, a multi-task\nsearch-based framework designed to enhance both query representation and tool\nretrieval accuracy. MassTool employs a two-tower architecture: a tool usage\ndetection tower that predicts the need for function calls, and a tool retrieval\ntower that leverages a query-centric graph convolution network (QC-GCN) for\neffective query-tool matching. It also incorporates search-based user intent\nmodeling (SUIM) to handle diverse and out-of-distribution queries, alongside an\nadaptive knowledge transfer (AdaKT) module for efficient multi-task learning.\nBy jointly optimizing tool usage detection loss, list-wise retrieval loss, and\ncontrastive regularization loss, MassTool establishes a robust dual-step\nsequential decision-making pipeline for precise query understanding. Extensive\nexperiments demonstrate its effectiveness in improving retrieval accuracy. Our\ncode is available at https://github.com/wxydada/MassTool.", "AI": {"tldr": "MassTool\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u4efb\u52a1\u641c\u7d22\u7684\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u5de5\u5177\u4ea4\u4e92\u7684\u6548\u679c\uff0c\u901a\u8fc7\u6539\u8fdb\u67e5\u8be2\u8868\u793a\u548c\u5de5\u5177\u68c0\u7d22\u7cbe\u786e\u5ea6\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "motivation": "\u5de5\u5177\u68c0\u7d22\u662f\u8ba9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u6548\u5730\u4e0e\u5916\u90e8\u5de5\u5177\u4ea4\u4e92\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5927\u591a\u6570\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u4e8e\u4f18\u5316\u5de5\u5177\u8868\u793a\uff0c\u5e38\u5ffd\u7565\u7cbe\u786e\u67e5\u8be2\u7406\u89e3\u7684\u91cd\u8981\u6027\u3002", "method": "MassTool\u91c7\u7528\u53cc\u5854\u67b6\u6784\uff1a\u5de5\u5177\u4f7f\u7528\u68c0\u6d4b\u5854\u548c\u5de5\u5177\u68c0\u7d22\u5854\u3002\u5de5\u5177\u4f7f\u7528\u68c0\u6d4b\u5854\u9884\u6d4b\u662f\u5426\u9700\u8981\u51fd\u6570\u8c03\u7528\uff0c\u800c\u5de5\u5177\u68c0\u7d22\u5854\u5229\u7528\u57fa\u4e8e\u67e5\u8be2\u7684\u4e2d\u5fc3\u56fe\u5377\u79ef\u7f51\u7edc\uff08QC-GCN\uff09\u8fdb\u884c\u9ad8\u6548\u7684\u67e5\u8be2-\u5de5\u5177\u5339\u914d\u3002\u540c\u65f6\uff0c\u5b83\u8fd8\u7ed3\u5408\u4e86\u57fa\u4e8e\u641c\u7d22\u7684\u7528\u6237\u610f\u56fe\u5efa\u6a21\uff08SUIM\uff09\u6765\u5904\u7406\u591a\u6837\u5316\u548c\u5206\u5e03\u5916\u7684\u67e5\u8be2\uff0c\u4ee5\u53ca\u81ea\u9002\u5e94\u77e5\u8bc6\u8f6c\u79fb\uff08AdaKT\uff09\u6a21\u5757\u8fdb\u884c\u6709\u6548\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5de5\u5177\u4f7f\u7528\u68c0\u6d4b\u635f\u5931\u3001\u5217\u8868\u5f0f\u68c0\u7d22\u635f\u5931\u548c\u5bf9\u6bd4\u6b63\u5219\u5316\u635f\u5931\uff0cMassTool\u5efa\u7acb\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u3001\u53cc\u6b65\u7684\u987a\u5e8f\u51b3\u7b56\u6d41\u7a0b\uff0c\u7528\u4ee5\u7cbe\u786e\u5730\u7406\u89e3\u67e5\u8be2\u3002\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u63d0\u5347\u68c0\u7d22\u7cbe\u786e\u5ea6\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "MassTool\u4e3a\u4e00\u4e2a\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u5de5\u5177\u4ea4\u4e92\u7684\u6709\u6548\u65b9\u6cd5\u63d0\u4f9b\u4e86\u521b\u65b0\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u67e5\u8be2\u8868\u793a\u548c\u5de5\u5177\u68c0\u7d22\u7684\u7cbe\u786e\u5ea6\u3002"}}
{"id": "2507.00521", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2507.00521", "abs": "https://arxiv.org/abs/2507.00521", "authors": ["Mugeng Liu", "Siqi Zhong", "Qi Yang", "Yudong Han", "Xuanzhe Liu", "Yun Ma"], "title": "\\texttt{WebANNS}: Fast and Efficient Approximate Nearest Neighbor Search in Web Browsers", "comment": "SIGIR 2025", "summary": "Approximate nearest neighbor search (ANNS) has become vital to modern AI\ninfrastructure, particularly in retrieval-augmented generation (RAG)\napplications. Numerous in-browser ANNS engines have emerged to seamlessly\nintegrate with popular LLM-based web applications, while addressing privacy\nprotection and challenges of heterogeneous device deployments. However, web\nbrowsers present unique challenges for ANNS, including computational\nlimitations, external storage access issues, and memory utilization\nconstraints, which state-of-the-art (SOTA) solutions fail to address\ncomprehensively.\n  We propose \\texttt{WebANNS}, a novel ANNS engine specifically designed for\nweb browsers. \\texttt{WebANNS} leverages WebAssembly to overcome computational\nbottlenecks, designs a lazy loading strategy to optimize data retrieval from\nexternal storage, and applies a heuristic approach to reduce memory usage.\nExperiments show that \\texttt{WebANNS} is fast and memory efficient, achieving\nup to $743.8\\times$ improvement in 99th percentile query latency over the SOTA\nengine, while reducing memory usage by up to 39\\%. Note that \\texttt{WebANNS}\ndecreases query time from 10 seconds to the 10-millisecond range in browsers,\nmaking in-browser ANNS practical with user-acceptable latency.", "AI": {"tldr": "WebANNS is a new ANNS engine for web browsers using WebAssembly, lazy loading, and heuristics to improve speed and reduce memory usage significantly over existing solutions.", "motivation": "\u7531\u4e8e\u73b0\u6709\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22(ANNS)\u7684\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u5168\u9762\u5e94\u5bf9\u6d4f\u89c8\u5668\u4e2d\u8ba1\u7b97\u9650\u5236\u3001\u5916\u90e8\u5b58\u50a8\u8bbf\u95ee\u95ee\u9898\u548c\u5185\u5b58\u5229\u7528\u7387\u7b49\u6311\u6218\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3a\u7f51\u9875\u6d4f\u89c8\u5668\u4e13\u95e8\u8bbe\u8ba1\u7684ANNS\u5f15\u64ceWebANNS\u3002", "method": "WebANNS\u5229\u7528WebAssembly\u514b\u670d\u8ba1\u7b97\u74f6\u9888\uff0c\u8bbe\u8ba1\u4e86\u61d2\u52a0\u8f7d\u7b56\u7565\u4ee5\u4f18\u5316\u5916\u90e8\u5b58\u50a8\u7684\u6570\u636e\u68c0\u7d22\uff0c\u5e76\u91c7\u53d6\u542f\u53d1\u5f0f\u65b9\u6cd5\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u5f15\u64ce\u76f8\u6bd4\uff0cWebANNS\u572899%\u7684\u67e5\u8be2\u5ef6\u8fdf\u4e0a\u63d0\u9ad8\u4e86\u9ad8\u8fbe743.8\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u4e86\u9ad8\u8fbe39%\uff0c\u67e5\u8be2\u65f6\u95f4\u4ece10\u79d2\u51cf\u5c11\u5230\u4e86\u6570\u5341\u6beb\u79d2\u7ea7\u522b\u3002", "conclusion": "WebANNS\u4f7f\u5f97\u6d4f\u89c8\u5668\u5185\u7684ANNS\u56e0\u7528\u6237\u53ef\u63a5\u53d7\u7684\u4f4e\u5ef6\u8fdf\u800c\u53d8\u5f97\u5b9e\u7528\u3002"}}
{"id": "2507.00535", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.00535", "abs": "https://arxiv.org/abs/2507.00535", "authors": ["Dietmar Jannach", "Amra Deli\u0107", "Francesco Ricci", "Markus Zanker"], "title": "Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support", "comment": "Submitted for publication", "summary": "More than twenty-five years ago, first ideas were developed on how to design\na system that can provide recommendations to groups of users instead of\nindividual users. Since then, a rich variety of algorithmic proposals were\npublished, e.g., on how to acquire individual preferences, how to aggregate\nthem, and how to generate recommendations for groups of users. However, despite\nthe rich literature on the topic, barely any examples of real-world group\nrecommender systems can be found. This lets us question common assumptions in\nacademic research, in particular regarding communication processes in a group\nand how recommendation-supported decisions are made. In this essay, we argue\nthat these common assumptions and corresponding system designs often may not\nmatch the needs or expectations of users. We thus call for a reorientation in\nthis research area, leveraging the capabilities of modern Generative AI\nassistants like ChatGPT. Specifically, as one promising future direction, we\nenvision group recommender systems to be systems where human group members\ninteract in a chat and an AI-based group recommendation agent assists the\ndecision-making process in an agentic way. Ultimately, this shall lead to a\nmore natural group decision-making environment and finally to wider adoption of\ngroup recommendation systems in practice.", "AI": {"tldr": "\u672c\u6587\u8d28\u7591\u5f53\u524d\u5c0f\u7ec4\u6210\u5458\u63a8\u8350\u7cfb\u7edf\u5047\u8bbe\uff0c\u63d0\u51fa\u5229\u7528ChatGPT\u7b49\u751f\u6210\u5f0fAI\u52a9\u7406\u5de5\u5177\uff0c\u901a\u8fc7AI\u63a8\u8350\u4ee3\u7406\u5e2e\u52a9\u5c0f\u7ec4\u6210\u5458\u505a\u51b3\u7b56\uff0c\u6700\u7ec8\u5b9e\u73b0\u66f4\u81ea\u7136\u7684\u5c0f\u7ec4\u51b3\u7b56\u73af\u5883\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e \u06af\u0631\u0648\u0647\u06cc \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u062f\u0647\u0646\u062f\u0647 \u0633\u06cc\u0633\u062a\u0645\u200c\u0647\u0627 \u0632\u06cc\u0627\u062f\u06cc \u062f\u0631 \u0627\u062f\u0628\u06cc\u0627\u062a \u0645\u0648\u062c\u0648\u062f \u0627\u0633\u062a\u060c \u0627\u0645\u0627 \u0647\u06cc\u0686 \u0646\u0645\u0648\u0646\u0647\u200c\u0627\u06cc \u0627\u0632 \u0633\u06cc\u0633\u062a\u0645\u200c\u0647\u0627\u06cc \u06af\u0631\u0648\u0647\u06cc \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u062f\u0647\u0646\u062f\u0647 \u062f\u0631 \u062f\u0646\u06cc\u0627\u06cc \u0648\u0627\u0642\u0639\u06cc \u06cc\u0627\u0641\u062a \u0646\u0645\u06cc\u200c\u0634\u0648\u062f. \u0627\u06cc\u0646 \u0627\u0645\u0631 \u0628\u0627\u0639\u062b \u0645\u06cc\u200c\u0634\u0648\u062f \u0645\u0627 \u062f\u0631 \u0645\u0648\u0631\u062f \u0645\u0631\u0627\u06a9\u0632 \u0627\u0631\u062a\u0628\u0627\u0637\u06cc \u062f\u0631 \u06af\u0631\u0648\u0647\u200c\u0647\u0627 \u0648 \u0646\u062d\u0648\u0647 \u062a\u0635\u0645\u06cc\u0645\u200c\u06af\u06cc\u0631\u06cc \u067e\u0634\u062a\u06cc\u0628\u0627\u0646\u06cc \u0634\u062f\u0647 \u062a\u0648\u0633\u0637 \u067e\u06cc\u0634\u0646\u0647\u0627\u062f\u0647\u0627 \u06a9\u0646\u062c\u06a9\u0627\u0648 \u0634\u0648\u06cc\u0645.", "method": "\u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u0646\u06af\u0631\u06cc \u062f\u0631 \u0627\u06cc\u0646 \u0632\u0645\u06cc\u0646\u0647 \u062a\u062d\u0642\u06cc\u0642\u06cc\u060c \u0646\u0648\u06cc\u0633\u0646\u062f\u06af\u0627\u0646 \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u0645\u06cc\u200c\u06a9\u0646\u0646\u062f \u06a9\u0647 \u0627\u0632 \u062a\u0648\u0627\u0646\u0627\u06cc\u06cc\u200c\u0647\u0627\u06cc ChatGPT \u0648 \u06a9\u0645\u06a9\u200c\u0647\u0627\u06cc \u0647\u0648\u0634 \u0645\u0635\u0646\u0648\u0639\u06cc \u062e\u0644\u0642\u200c\u0634\u062f\u0647 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0646\u0646\u062f \u062a\u0627 \u0633\u06cc\u0633\u062a\u0645\u200c\u0647\u0627\u06cc \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u062f\u0647\u0646\u062f\u0647 \u06af\u0631\u0648\u0647\u06cc \u0631\u0627 \u062a\u063a\u06cc\u06cc\u0631 \u062f\u0647\u0646\u062f.", "result": "\u0646\u062a\u06cc\u062c\u0647 \u0645\u0648\u0631\u062f \u0627\u0646\u062a\u0638\u0627\u0631 \u0627\u0632 \u0627\u06cc\u0646 \u0631\u0648\u0634 \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0633\u06cc\u0633\u062a\u0645\u200c\u0647\u0627\u06cc \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u062f\u0647\u0646\u062f\u0647 \u06af\u0631\u0648\u0647\u06cc \u0633\u06cc\u0633\u062a\u0645\u200c\u0647\u0627\u06cc\u06cc \u0628\u0627\u0634\u0646\u062f \u06a9\u0647 \u062f\u0631 \u0622\u0646\u0647\u0627 \u0627\u0639\u0636\u0627\u06cc \u06af\u0631\u0648\u0647 \u0628\u0627 \u06a9\u0645\u06a9 \u06cc\u06a9 \u06a9\u0627\u0631\u06af\u0632\u0627\u0631 \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u062f\u0647\u0646\u062f\u0647 \u0647\u0648\u0634 \u0645\u0635\u0646\u0648\u0639\u06cc \u0628\u0647 \u0635\u0648\u0631\u062a \u062e\u0648\u062f\u06a9\u0627\u0631 \u062f\u0631 \u0686\u062a\u200c\u0647\u0627 \u062a\u0639\u0627\u0645\u0644 \u0645\u06cc\u200c\u06a9\u0646\u0646\u062f \u0648 \u062f\u0631 \u0646\u0647\u0627\u06cc\u062a \u0628\u0647 \u06cc\u06a9 \u0645\u062d\u06cc\u0637 \u062a\u0635\u0645\u06cc\u0645\u200c\u06af\u06cc\u0631\u06cc \u0637\u0628\u06cc\u0639\u06cc\u200c\u062a\u0631 \u0628\u0631\u0627\u06cc \u06af\u0631\u0648\u0647\u200c\u0647\u0627 \u0645\u0646\u062c\u0631 \u0645\u06cc\u200c\u0634\u0648\u0646\u062f.", "conclusion": "\u0646\u0648\u06cc\u0633\u0646\u062f\u06af\u0627\u0646 \u0628\u0631\u0627\u06cc \u0627\u062a\u062e\u0627\u0630 \u0633\u06cc\u0633\u062a\u0645\u200c\u0647\u0627\u06cc \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u062f\u0647\u0646\u062f\u0647 \u06af\u0631\u0648\u0647\u06cc \u062f\u0631 \u0639\u0645\u0644 \u0628\u0647 \u062f\u0639\u0648\u062a \u0642\u0648\u06cc\u200c\u062a\u0631\u06cc \u0645\u06cc\u200c\u06a9\u0646\u0646\u062f \u0648 \u0645\u0639\u062a\u0642\u062f \u0647\u0633\u062a\u0646\u062f \u06a9\u0647 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0627\u0632 \u0647\u0648\u0634 \u0645\u0635\u0646\u0648\u0639\u06cc \u0645\u06cc\u200c\u062a\u0648\u0627\u0646\u062f \u0628\u0647 \u0627\u06cc\u0646 \u0627\u0645\u0631 \u06a9\u0645\u06a9 \u06a9\u0646\u062f."}}
{"id": "2507.00543", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.00543", "abs": "https://arxiv.org/abs/2507.00543", "authors": ["Leila Tavakoli", "Hamed Zamani"], "title": "Reliable Annotations with Less Effort: Evaluating LLM-Human Collaboration in Search Clarifications", "comment": "9 pages,5 figures", "summary": "Despite growing interest in using large language models (LLMs) to automate\nannotation, their effectiveness in complex, nuanced, and multi-dimensional\nlabelling tasks remains relatively underexplored. This study focuses on\nannotation for the search clarification task, leveraging a high-quality,\nmulti-dimensional dataset that includes five distinct fine-grained annotation\nsubtasks. Although LLMs have shown impressive capabilities in general settings,\nour study reveals that even state-of-the-art models struggle to replicate\nhuman-level performance in subjective or fine-grained evaluation tasks. Through\na systematic assessment, we demonstrate that LLM predictions are often\ninconsistent, poorly calibrated, and highly sensitive to prompt variations. To\naddress these limitations, we propose a simple yet effective human-in-the-loop\n(HITL) workflow that uses confidence thresholds and inter-model disagreement to\nselectively involve human review. Our findings show that this lightweight\nintervention significantly improves annotation reliability while reducing human\neffort by up to 45%, offering a relatively scalable and cost-effective yet\naccurate path forward for deploying LLMs in real-world evaluation settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u867d\u7136\u5f3a\u4f46\u5728\u4e3b\u89c2\u6216\u7ec6\u7c92\u5ea6\u4efb\u52a1\u4e0a\u96be\u4ee5\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u4eba\u5de5\u8f85\u52a9\u6d41\u7a0b\uff0c\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u6d41\u7a0b\u80fd\u63d0\u5347\u6807\u6ce8\u53ef\u9760\u6027\u5e76\u51cf\u5c11\u4eba\u529b\u6295\u5165\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u6ce8\u89e3\u9886\u57df\u9010\u6e10\u53d7\u5230\u5173\u6ce8\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5176\u5728\u4e00\u4e2a\u5177\u4f53\u4efb\u52a1\u2014\u2014\u641c\u7d22\u6f84\u6e05\u4efb\u52a1\u2014\u2014\u4e2d\u7684\u8868\u73b0\uff0c\u8bd5\u56fe\u89e3\u51b3LLMs\u5728\u590d\u6742\u591a\u7ef4\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u5305\u542b\u4e94\u4e2a\u7ec6\u7c92\u5ea6\u6807\u6ce8\u5b50\u4efb\u52a1\u7684\u9ad8\u8d28\u91cf\u591a\u7ef4\u5ea6\u6570\u636e\u96c6\uff0c\u5bf9LLMs\u8fdb\u884c\u4e86\u7cfb\u7edf\u6d4b\u8bc4\uff0c\u5e76\u901a\u8fc7\u53d7\u4eba\u76d1\u7763\u7684\uff08HITL\uff09\u5de5\u4f5c\u6d41\u7a0b\u6765\u4f18\u5316LLMs\u7684\u6807\u6ce8\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u7684\u9884\u6d4b\u7ed3\u679c\u5e38\u5e38\u4e0d\u4e00\u81f4\u3001\u6821\u51c6\u5ea6\u5dee\u4e14\u5bf9\u63d0\u793a\u53d8\u5f02\u654f\u611f\u3002\u901a\u8fc7\u91c7\u7528\u4eba\u5de5\u8f85\u52a9\u6d41\u7a0b\uff0c\u6807\u6ce8\u7684\u53ef\u9760\u6027\u5f97\u5230\u4e86\u63d0\u5347\uff0c\u5e76\u51cf\u5c11\u4e86\u9ad8\u8fbe45%\u7684\u4eba\u529b\u6295\u5165\u3002", "conclusion": "\u5c3d\u7ba1LLMs\u5728\u4e00\u822c\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u4e8e\u4e3b\u89c2\u6216\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\u5b83\u4eec\u4ecd\u96be\u4ee5\u590d\u5236\u4eba\u7c7b\u7684\u8868\u73b0\u3002\u672c\u7814\u7a76\u7684HITL\u6d41\u7a0b\u4e3a\u5c06LLMs\u5728\u5b9e\u9645\u8bc4\u4f30\u73af\u5883\u4e2d\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u79cd\u76f8\u5bf9\u53ef\u6269\u5c55\u3001\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u7cbe\u51c6\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.00715", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2507.00715", "abs": "https://arxiv.org/abs/2507.00715", "authors": ["Chaoqun Yang", "Xinyu Lin", "Wenjie Wang", "Yongqi Li", "Teng Sun", "Xianjing Han", "Tat-Seng Chua"], "title": "EARN: Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens", "comment": "Accepted by KDD 2025", "summary": "Large Language Model-based generative recommendation (LLMRec) has achieved\nnotable success, but it suffers from high inference latency due to massive\ncomputational overhead and memory pressure of KV Cache. Existing KV Cache\nreduction methods face critical limitations: cache compression offers marginal\nacceleration given recommendation tasks' short decoding steps, while prompt\ncompression risks discarding vital interaction history. Through systematic\nanalysis of attention patterns in LLMRec, we uncover two pivotal insights: 1)\nlayer-wise attention sparsity inversion where early layers retain dense\ninformative patterns while later layers exhibit high redundancy, and 2) dual\nattention sinks phenomenon where attention scores concentrate on both head and\ntail tokens of input sequences. Motivated by these insights, we propose EARN,\nan efficient inference framework that leverages the early layers to compress\ninformation into register tokens placed at the input sequence boundaries, then\nfocuses solely on these tokens in the subsequent layers. Extensive experiments\non three datasets, two LLMRec methods and two LLM architectures demonstrate\nEARN's superiority, achieving up to 3.79x speedup and 80.8% KV Cache reduction\nwith better accuracy than the general finetuning approach. Our work bridges the\nefficiency-effectiveness gap in LLMRec, offering practical deployment\nadvantages for industrial scenarios.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u5b58\u5728\u7684\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u63a8\u7406\u6846\u67b6EARN,\u5229\u7528\u5148\u524d\u5c42\u7684\u4fe1\u606f\u538b\u7f29\u548c\u96c6\u4e2d\u5904\u7406\u8fb9\u754ctoken,\u5b9e\u73b0\u52a0\u901f\u548c\u964d\u4f4e\u5185\u5b58\u538b\u529b\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u56e0\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u548cKV\u7f13\u5b58\u5185\u5b58\u538b\u529b\u800c\u5b58\u5728\u9ad8\u63a8\u7406\u5ef6\u8fdf,\u538b\u7f29\u65b9\u6cd5\u6548\u679c\u6709\u9650\u3002", "method": "\u5206\u6790\u6ce8\u610f\u529b\u6a21\u5f0f\u540e,\u63d0\u51fa\u6846\u67b6EARN,\u901a\u8fc7\u538b\u7f29\u4fe1\u606f\u5230\u8f93\u5165\u5e8f\u5217\u7684\u8fb9\u754ctoken,\u5e76\u53ea\u5173\u6ce8\u8fd9\u4e9btoken\u6765\u52a0\u901f\u3002", "result": "\u4e09\u4e2a\u6570\u636e\u96c6\u3001\u4e24\u79cdLLM\u63a8\u8350\u65b9\u6cd5\u548c\u4e24\u79cdLLM\u67b6\u6784\u7684\u5b9e\u9a8c\u8868\u660e,\u52a0\u901f\u9ad8\u8fbe3.79\u500d,\u7f13\u5b58\u51cf\u5c1180.8%,\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u7387\u3002", "conclusion": "EARN\u5f25\u8865\u4e86\u6548\u7387\u4e0e\u6548\u679c\u4e4b\u95f4\u7684\u5dee\u8ddd,\u4e3aLLM\u63a8\u8350\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u4f18\u52bf\u3002"}}
{"id": "2507.00938", "categories": ["cs.IR", "cs.AI", "cs.DB", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.00938", "abs": "https://arxiv.org/abs/2507.00938", "authors": ["Zihao Sun", "Meng Fang", "Ling Chen"], "title": "WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks", "comment": "10 pages, 9 figures, 4 tables", "summary": "Recent progress in large language models (LLMs) has enabled the development\nof autonomous web agents capable of navigating and interacting with real\nwebsites. However, evaluating such agents remains challenging due to the\ninstability and inconsistency of existing benchmarks, which often rely on\ndynamic content or oversimplified simulations. In this work, we introduce\nWebArXiv, a static and time-invariant benchmark comprising 275 web-based tasks\ngrounded in the arXiv platform. WebArXiv ensures reproducible and reliable\nevaluation by anchoring tasks in fixed web snapshots with deterministic ground\ntruths and standardized action trajectories. Through behavioral analysis, we\nidentify a common failure mode, Rigid History Reflection, where agents\nover-rely on fixed interaction histories. To address this, we propose a\nlightweight dynamic reflection mechanism that allows agents to selectively\nretrieve relevant past steps during decision-making. We evaluate ten\nstate-of-the-art web agents on WebArXiv. Results demonstrate clear performance\ndifferences across agents and validate the effectiveness of our proposed\nreflection strategy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86WebArXiv\uff0c\u4e00\u4e2a\u57fa\u4e8e\u9759\u6001\u548c\u4e0d\u968f\u65f6\u95f4\u6539\u53d8\u7684arXiv\u7f51\u7edc\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e2a\u5e38\u89c1\u9519\u8bef\u6a21\u5f0f\uff1a\u521a\u6027\u7684\u5386\u53f2\u56de\u6eaf\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u52a8\u6001\u53cd\u5c04\u673a\u5236\u6765\u89e3\u51b3\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u548c\u8fc7\u4e8e\u7b80\u5316\uff0c\u8bc4\u4f30\u81ea\u4e3b\u7f51\u9875\u4ee3\u7406\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u6240\u4ee5\u63d0\u51fa\u4e00\u4e2a\u9759\u6001\u4e14\u65f6\u95f4\u4e0d\u53d8\u7684\u57fa\u51c6WebArXiv\uff0c\u8be5\u57fa\u51c6\u5305\u542b\u57fa\u4e8earXiv\u5e73\u53f0\u7684\u7f51\u9875\u4efb\u52a1\u3002", "method": "\u901a\u8fc7\u9759\u6001\u7684Web\u5feb\u7167\u548c\u786e\u5b9a\u7684\u771f\u5b9e\u60c5\u51b5\u53ca\u6807\u51c6\u5316\u7684\u52a8\u4f5c\u8f68\u8ff9\uff0cWebArXiv\u786e\u4fdd\u4e86\u53ef\u91cd\u590d\u548c\u53ef\u9760\u7684\u8bc4\u4f30\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cd\u91cf\u7ea7\u7684\u52a8\u6001\u53cd\u5c04\u673a\u5236\u6765\u4f7f\u4ee3\u7406\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u9009\u602a\u6027\u83b7\u53d6\u76f8\u5173\u8fc7\u53bb\u6b65\u9aa4\u3002", "result": "\u901a\u8fc7WebArXiv\u5bf9\u5341\u4e2a\u6700\u5148\u8fdb\u7684\u7f51\u7edc\u4ee3\u7406\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u4ee3\u7406\u4e4b\u95f4\u6709\u660e\u663e\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u53cd\u5c04\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "WebArXiv\u4e3a\u4e00\u4e2a\u8bc4\u4f30\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u63d0\u4f9b\u4e86\u7a33\u5b9a\u7684\u57fa\u51c6\uff0c\u5e76\u63ed\u793a\u4e86\u7f51\u7edc\u4ee3\u7406\u5b58\u5728\u7684\u95ee\u9898\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7b56\u7565\uff0c\u8fd9\u5bf9\u63d0\u9ad8\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u7684\u6027\u80fd\u975e\u5e38\u6709\u5e2e\u52a9\u3002"}}
