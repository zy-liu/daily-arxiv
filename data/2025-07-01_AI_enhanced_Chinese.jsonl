{"id": "2506.22648", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22648", "abs": "https://arxiv.org/abs/2506.22648", "authors": ["Pedro R. Pires", "Tiago A. Almeida"], "title": "Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems", "comment": "Accepted for publication in Applied Soft Computing (ASOC), 49 pages,\n  14 figures", "summary": "Over the past decade, recommender systems have experienced a surge in\npopularity. Despite notable progress, they grapple with challenging issues,\nsuch as high data dimensionality and sparseness. Representing users and items\nas low-dimensional embeddings learned via neural networks has become a leading\nsolution. However, while recent studies show promising results, many approaches\nrely on complex architectures or require content data, which may not always be\navailable. This paper presents Interact2Vec, a novel neural network-based model\nthat simultaneously learns distributed embeddings for users and items while\ndemanding only implicit feedback. The model employs state-of-the-art strategies\nthat natural language processing models commonly use to optimize the training\nphase and enhance the final embeddings. Two types of experiments were conducted\nregarding the extrinsic and intrinsic quality of the model. In the former, we\nbenchmarked the recommendations generated by Interact2Vec's embeddings in a\ntop-$N$ ranking problem, comparing them with six other recommender algorithms.\nThe model achieved the second or third-best results in 30\\% of the datasets,\nbeing competitive with other recommenders, and has proven to be very efficient\nwith an average training time reduction of 274\\% compared to other\nembedding-based models. Later, we analyzed the intrinsic quality of the\nembeddings through similarity tables. Our findings suggest that Interact2Vec\ncan achieve promising results, especially on the extrinsic task, and is an\nexcellent embedding-generator model for scenarios of scarce computing\nresources, enabling the learning of item and user embeddings simultaneously and\nefficiently.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Interact2Vec\uff0c\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u63a8\u8350\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u7528\u6237\u548c\u9879\u76ee\u7684\u5206\u5e03\u5f0f\u5d4c\u5165\uff0c\u53ea\u9700\u8981\u9690\u5f0f\u53cd\u9988\uff0c\u5e76\u4f7f\u7528\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u5148\u8fdb\u7b56\u7565\u6765\u4f18\u5316\u8bad\u7ec3\u548c\u63d0\u5347\u5d4c\u5165\u8d28\u91cf\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u7740\u6570\u636e\u9ad8\u7ef4\u5ea6\u548c\u7a00\u758f\u6027\u7684\u6311\u6218\uff0c\u4f4e\u7ef4\u5d4c\u5165\u6280\u672f\u88ab\u7528\u4f5c\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u7684\u8bb8\u591a\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u590d\u6742\u67b6\u6784\u6216\u5185\u5bb9\u6570\u636e\uff0c\u53ef\u80fd\u65e0\u6cd5\u59cb\u7ec8\u83b7\u5f97\u3002", "method": "Interact2Vec\u6a21\u578b\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u7528\u6237\u548c\u9879\u76ee\u7684\u5206\u5e03\u5f0f\u5d4c\u5165\uff0c\u53ea\u9700\u8981\u9690\u5f0f\u53cd\u9988\uff0c\u5e76\u91c7\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u5e38\u89c1\u7684\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u548c\u63d0\u5347\u6700\u7ec8\u5d4c\u5165\u3002", "result": "\u5728extrinsic\u8d28\u91cf\u5b9e\u9a8c\u4e2d\uff0cInteract2Vec\u572830%\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e0e\u5176\u4ed6\u63a8\u8350\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5e73\u5747\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e86274%\u3002\u5728intrinsic\u8d28\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u901a\u8fc7\u76f8\u4f3c\u5ea6\u8868\u683c\u5206\u6790\u8868\u660e\uff0cInteract2Vec\u5728extrinsic\u4efb\u52a1\u4e0a\u80fd\u591f\u53d6\u5f97\u826f\u597d\u7684\u7ed3\u679c\u3002", "conclusion": "Interact2Vec\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u7528\u6237\u548c\u9879\u76ee\u5d4c\u5165\uff0c\u5c24\u5176\u5728\u8ba1\u7b97\u8d44\u6e90\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5d4c\u5165\u751f\u6210\u6a21\u578b\u3002"}}
{"id": "2506.23026", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.23026", "abs": "https://arxiv.org/abs/2506.23026", "authors": ["Yongsheng Lian"], "title": "Machine Assistant with Reliable Knowledge: Enhancing Student Learning via RAG-based Retrieval", "comment": null, "summary": "We present Machine Assistant with Reliable Knowledge (MARK), a\nretrieval-augmented question-answering system designed to support student\nlearning through accurate and contextually grounded responses. The system is\nbuilt on a retrieval-augmented generation (RAG) framework, which integrates a\ncurated knowledge base to ensure factual consistency. To enhance retrieval\neffectiveness across diverse question types, we implement a hybrid search\nstrategy that combines dense vector similarity with sparse keyword-based\nretrieval. This dual-retrieval mechanism improves robustness for both general\nand domain-specific queries. The system includes a feedback loop in which\nstudents can rate responses and instructors can review and revise them.\nInstructor corrections are incorporated into the retrieval corpus, enabling\nadaptive refinement over time. The system was deployed in a classroom setting\nas a substitute for traditional office hours, where it successfully addressed a\nbroad range of student queries. It was also used to provide technical support\nby integrating with a customer-specific knowledge base, demonstrating its\nability to handle routine, context-sensitive tasks in applied domains. MARK is\npublicly accessible at https://app.eduquery.ai.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MARK\uff0c\u4e00\u4e2a\u901a\u8fc7\u53ef\u9760\u77e5\u8bc6\u589e\u5f3a\u7684\u95ee\u7b54\u7cfb\u7edf\uff0c\u7528\u4e8e\u652f\u6301\u5b66\u751f\u7684\u5b66\u4e60\u3002", "motivation": "\u63d0\u51faMARK\u7cfb\u7edf\uff0c\u65e8\u5728\u901a\u8fc7\u51c6\u786e\u4e14\u6709\u4e0a\u4e0b\u6587\u6839\u636e\u7684\u56de\u7b54\u6765\u652f\u6301\u5b66\u751f\u7684\u5b66\u4e60\u3002", "method": "MARK\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6846\u67b6\uff0c\u6574\u5408\u4e86\u7ecf\u8fc7\u7b5b\u9009\u7684\u77e5\u8bc6\u5e93\u4ee5\u786e\u4fdd\u4e8b\u5b9e\u4e00\u81f4\u6027\u3002\u91c7\u7528\u6df7\u5408\u641c\u7d22\u7b56\u7565\uff0c\u7ed3\u5408\u5bc6\u96c6\u5411\u91cf\u76f8\u4f3c\u6027\u548c\u7a00\u758f\u5173\u952e\u8bcd\u68c0\u7d22\uff0c\u589e\u5f3a\u68c0\u7d22\u6709\u6548\u6027\u3002", "result": "\u7cfb\u7edf\u90e8\u7f72\u5728\u6559\u5ba4\u73af\u5883\u4e2d\uff0c\u6210\u529f\u5904\u7406\u4e86\u5e7f\u6cdb\u7684\u5b66\u751f\u67e5\u8be2\uff0c\u5e76\u5c55\u73b0\u51fa\u5904\u7406\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u7684\u80fd\u529b\u3002", "conclusion": "MARK\u7cfb\u7edf\u80fd\u591f\u9002\u5e94\u6027\u5730\u6539\u8fdb\uff0c\u6709\u6548\u652f\u6301\u5b66\u751f\u5b66\u4e60\u548c\u63d0\u4f9b\u6280\u672f\u652f\u6301\uff0c\u662f\u4f20\u7edf\u529e\u516c\u5ba4\u5c0f\u65f6\u7684\u826f\u597d\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.23060", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.23060", "abs": "https://arxiv.org/abs/2506.23060", "authors": ["Zhibo Fan", "Hongtao Lin", "Haoyu Chen", "Bowen Deng", "Hedi Xia", "Yuke Yan", "James Li"], "title": "Synergizing Implicit and Explicit User Interests: A Multi-Embedding Retrieval Framework at Pinterest", "comment": "KDD 2025", "summary": "Industrial recommendation systems are typically composed of multiple stages,\nincluding retrieval, ranking, and blending. The retrieval stage plays a\ncritical role in generating a high-recall set of candidate items that covers a\nwide range of diverse user interests. Effectively covering the diverse and\nlong-tail user interests within this stage poses a significant challenge:\ntraditional two-tower models struggle in this regard due to limited user-item\nfeature interaction and often bias towards top use cases. To address these\nissues, we propose a novel multi-embedding retrieval framework designed to\nenhance user interest representation by generating multiple user embeddings\nconditioned on both implicit and explicit user interests. Implicit interests\nare captured from user history through a Differentiable Clustering Module\n(DCM), whereas explicit interests, such as topics that the user has followed,\nare modeled via Conditional Retrieval (CR). These methodologies represent a\nform of conditioned user representation learning that involves condition\nrepresentation construction and associating the target item with the relevant\nconditions. Synergizing implicit and explicit user interests serves as a\ncomplementary approach to achieve more effective and comprehensive candidate\nretrieval as they benefit on different user segments and extract conditions\nfrom different but supplementary sources. Extensive experiments and A/B testing\nreveal significant improvements in user engagements and feed diversity metrics.\nOur proposed framework has been successfully deployed on Pinterest home feed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u591a\u5d4c\u5165\u68c0\u7d22\u6846\u67b6\u4ee5\u589e\u5f3a\u7528\u6237\u5174\u8da3\u8868\u793a\uff0c\u901a\u8fc7\u5dee\u5f02\u5316\u805a\u7c7b\u6a21\u5757\uff08DCM\uff09\u6355\u6349\u9690\u5f0f\u5174\u8da3\uff0c\u5e76\u901a\u8fc7\u6761\u4ef6\u68c0\u7d22\uff08CR\uff09\u5904\u7406\u660e\u786e\u5174\u8da3\uff08\u5982\u7528\u6237\u8ba2\u9605\u7684\u4e3b\u9898\uff09\uff0c\u4ece\u800c\u63d0\u9ad8\u5019\u9009\u7269\u54c1\u68c0\u7d22\u7684\u6709\u6548\u6027\u548c\u5168\u9762\u6027\u3002", "motivation": "\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u68c0\u7d22\u9636\u6bb5\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u4f20\u7edf\u53cc\u5854\u6a21\u578b\u96be\u4ee5\u6709\u6548\u8986\u76d6\u591a\u6837\u5316\u548c\u957f\u5c3e\u7528\u6237\u5174\u8da3\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u521b\u65b0\u7684\u591a\u5d4c\u5165\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5dee\u5f02\u5316\u805a\u7c7b\u6a21\u5757\uff08DCM\uff09\u548c\u6761\u4ef6\u68c0\u7d22\uff08CR\uff09\u7684\u9690\u5f0f\u548c\u663e\u5f0f\u7528\u6237\u5174\u8da3\u8868\u793a\uff0c\u589e\u5f3a\u7528\u6237\u5174\u8da3\u7684\u5efa\u6a21\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u548cA/B\u6d4b\u8bd5\u83b7\u5f97\u663e\u8457\u7684\u7528\u6237\u53c2\u4e0e\u5ea6\u63d0\u5347\u548c\u5185\u5bb9\u591a\u6837\u6027\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u5df2\u5728Pinterest\u4e3b\u4fe1\u606f\u6d41\u4e2d\u5f97\u5230\u6210\u529f\u90e8\u7f72\uff0c\u663e\u793a\u51fa\u8be5\u6846\u67b6\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u6709\u6548\u6027\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u7684\u80fd\u529b\u3002"}}
{"id": "2506.23085", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23085", "abs": "https://arxiv.org/abs/2506.23085", "authors": ["Saeid Aghasoleymani Najafabadi"], "title": "Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences", "comment": null, "summary": "The purpose of this paper is to explore a multi-modal approach to enhancing\nlive broadcast engagement by developing a short video recommendation system\nthat incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user\npreferences. In order to provide personalized recommendations tailored to\nindividual interests, the proposed system takes into account user interaction\ndata, video content features, and contextual information. With the aid of a\nhybrid approach combining collaborative filtering and content-based filtering\ntechniques, the system is able to capture nuanced relationships between users,\nvideo attributes, and engagement patterns. Three datasets are used to evaluate\nthe effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to\nbaseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the\nproposed MMGCN-based model shows superior performance. A notable feature of the\nproposed model is that it outperforms all baseline methods in capturing diverse\nuser preferences and making accurate, personalized recommendations, resulting\nin a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1\nscore of 0.197. We emphasize the importance of multi-modal integration and\nuser-centric approaches in advancing recommender systems, emphasizing the role\nthey play in enhancing content discovery and audience interaction on live\nbroadcast platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u7528\u6237\u504f\u597d\u3001\u4ea4\u4e92\u6570\u636e\u3001\u89c6\u9891\u5185\u5bb9\u7279\u5f81\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\uff0c\u8fd0\u7528\u4e86\u591a\u6a21\u6001\u56fe\u5377\u79ef\u7f51\u7edcMMGCN\u4ee5\u53ca\u534f\u540c\u8fc7\u6ee4\u548c\u57fa\u4e8e\u5185\u5bb9\u7684\u8fc7\u6ee4\u6280\u672f\uff0c\u65e8\u5728\u63d0\u9ad8\u76f4\u64ad\u4e92\u52a8\u6027\uff0c\u5e76\u5206\u522b\u5728Kwai\u3001TikTok\u548cMovieLens\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u63a8\u8350\u6a21\u578b\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u5305\u62ec\u591a\u6a21\u6001\u56fe\u5377\u79ef\u7f51\u7edc\uff08MMGCN\uff09\u548c\u7528\u6237\u504f\u597d\u7684\u77ed\u89c6\u9891\u63a8\u8350\u7cfb\u7edf\u6765\u589e\u5f3a\u76f4\u64ad\u4e92\u52a8\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u91c7\u7528\u878d\u5408\u591a\u6a21\u6001\u6570\u636e\uff08\u5305\u62ec\u7528\u6237\u4ea4\u4e92\u6570\u636e\u3001\u89c6\u9891\u5185\u5bb9\u7279\u5f81\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff09\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u534f\u540c\u8fc7\u6ee4\u548c\u57fa\u4e8e\u5185\u5bb9\u7684\u8fc7\u6ee4\u6280\u672f\u6765\u751f\u6210\u63a8\u8350\u3002", "result": "\u8bc4\u4ef7\u7cfb\u7edf\u6709\u6548\u6027\u7684\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u4e8eDeepFM\u3001Wide & Deep\u3001LightGBM\u548cXGBoost\u7b49\u57fa\u7ebf\u6a21\u578b\uff0cMMGCN\u6a21\u578b\u5728Kwai F1\u5f97\u52060.574\u3001TikTok F1\u5f97\u52060.506\u548cMovieLens F1\u5f97\u52060.197\u4e0a\u5747\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u591a\u6a21\u6001\u96c6\u6210\u548c\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u5728\u63a8\u8fdb\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u5728\u589e\u5f3a\u5185\u5bb9\u53d1\u73b0\u548c\u89c2\u4f17\u5728\u76f4\u64ad\u5e73\u53f0\u4e0a\u7684\u4e92\u52a8\u65b9\u9762\u3002"}}
{"id": "2506.23090", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23090", "abs": "https://arxiv.org/abs/2506.23090", "authors": ["Langming Liu", "Wanyu Wang", "Chi Zhang", "Bo Li", "Hongzhi Yin", "Xuetao Wei", "Wenbo Su", "Bo Zheng", "Xiangyu Zhao"], "title": "Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems", "comment": "KDD 2025", "summary": "Online advertising in recommendation platforms has gained significant\nattention, with a predominant focus on channel recommendation and budget\nallocation strategies. However, current offline reinforcement learning (RL)\nmethods face substantial challenges when applied to sparse advertising\nscenarios, primarily due to severe overestimation, distributional shifts, and\noverlooking budget constraints. To address these issues, we propose MTORL, a\nnovel multi-task offline RL model that targets two key objectives. First, we\nestablish a Markov Decision Process (MDP) framework specific to the nuances of\nadvertising. Then, we develop a causal state encoder to capture dynamic user\ninterests and temporal dependencies, facilitating offline RL through\nconditional sequence modeling. Causal attention mechanisms are introduced to\nenhance user sequence representations by identifying correlations among causal\nstates. We employ multi-task learning to decode actions and rewards,\nsimultaneously addressing channel recommendation and budget allocation.\nNotably, our framework includes an automated system for integrating these tasks\ninto online advertising. Extensive experiments on offline and online\nenvironments demonstrate MTORL's superiority over state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aMTORL\u7684\u65b0\u578b\u591a\u4efb\u52a1\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u63a8\u8350\u5e73\u53f0\u5728\u7ebf\u5e7f\u544a\u4e2d\u7684\u9884\u7b97\u5206\u914d\u548c\u6e20\u9053\u63a8\u8350\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7a00\u758f\u5e7f\u544a\u573a\u666f\u4e0b\u9047\u5230\u7684\u8fc7\u5ea6\u4f30\u8ba1\u3001\u5206\u5e03\u504f\u79fb\u548c\u9884\u7b97\u7ea6\u675f\u7b49\u6311\u6218\u3002", "motivation": "\u7531\u4e8e\u76ee\u524d\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u7a00\u758f\u5e7f\u544a\u573a\u666f\u65f6\u9762\u4e34\u8fc7\u5ea6\u4f30\u8ba1\u3001\u5206\u5e03\u504f\u79fb\u548c\u5ffd\u7565\u9884\u7b97\u7ea6\u675f\u7b49\u96be\u9898\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6587\u7ae0\u5efa\u7acb\u4e86\u4e00\u4e2a\u7279\u5b9a\u4e8e\u5e7f\u544a\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u56e0\u679c\u72b6\u6001\u7f16\u7801\u5668\u6765\u6355\u6349\u7528\u6237\u7684\u52a8\u6001\u5174\u8da3\u548c\u65f6\u5e8f\u4f9d\u8d56\u6027\u3002\u4e3a\u6b64\u4f7f\u7528\u4e86\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u6765\u589e\u5f3a\u7528\u6237\u5e8f\u5217\u8868\u793a\uff0c\u540c\u65f6\u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u6765\u89e3\u7801\u52a8\u4f5c\u548c\u5956\u52b1\u3002", "result": "\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u73af\u5883\u4e2d\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMTORL\u5728\u6548\u7387\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "MTORL\u6a21\u578b\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5728\u7ebf\u5e7f\u544a\u4e2d\u7684\u63a8\u8350\u548c\u9884\u7b97\u5206\u914d\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u7a00\u758f\u5e7f\u544a\u6570\u636e\u548c\u9884\u7b97\u9650\u5236\u65b9\u9762\u7684\u6311\u6218\uff0c\u4ee3\u8868\u4e86\u5904\u7406\u6b64\u7c7b\u95ee\u9898\u7684\u4e00\u4e2a\u8fdb\u6b65\u3002"}}
{"id": "2506.23170", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23170", "abs": "https://arxiv.org/abs/2506.23170", "authors": ["Jaime Hieu Do", "Trung-Hoang Le", "Hady W. Lauw"], "title": "Compositions of Variant Experts for Integrating Short-Term and Long-Term Preferences", "comment": null, "summary": "In the online digital realm, recommendation systems are ubiquitous and play a\ncrucial role in enhancing user experience. These systems leverage user\npreferences to provide personalized recommendations, thereby helping users\nnavigate through the paradox of choice. This work focuses on personalized\nsequential recommendation, where the system considers not only a user's\nimmediate, evolving session context, but also their cumulative historical\nbehavior to provide highly relevant and timely recommendations. Through an\nempirical study conducted on diverse real-world datasets, we have observed and\nquantified the existence and impact of both short-term (immediate and\ntransient) and long-term (enduring and stable) preferences on users' historical\ninteractions. Building on these insights, we propose a framework that combines\nshort- and long-term preferences to enhance recommendation performance, namely\nCompositions of Variant Experts (CoVE). This novel framework dynamically\nintegrates short- and long-term preferences through the use of different\nspecialized recommendation models (i.e., experts). Extensive experiments\nshowcase the effectiveness of the proposed methods and ablation studies further\ninvestigate the impact of variant expert types.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCoVE\u7684\u63a8\u8350\u7cfb\u7edf\u6846\u67b6\uff0c\u5b83\u80fd\u7ed3\u5408\u77ed\u671f\u548c\u957f\u671f\u7528\u6237\u504f\u597d\uff0c\u4ece\u800c\u63d0\u9ad8\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u5728\u5728\u7ebf\u6570\u5b57\u9886\u57df\u4e2d\uff0c\u63a8\u8350\u7cfb\u7edf\u5bf9\u4e8e\u6539\u5584\u7528\u6237\u4f53\u9a8c\u53d1\u6325\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u8003\u8651\u7528\u6237\u7d2f\u79ef\u7684\u5386\u53f2\u884c\u4e3a\u548c\u5373\u65f6\u4f1a\u8bdd\u4e0a\u4e0b\u6587\u6765\u63d0\u4f9b\u76f8\u5173\u53ca\u65f6\u7684\u63a8\u8350\u3002", "method": "\u57fa\u4e8e\u5bf9\u4e0d\u540c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e86\u77ed\u671f\u548c\u957f\u671f\u504f\u597d\u7684\u5b58\u5728\u53ca\u5176\u5bf9\u7528\u6237\u5386\u53f2\u4ea4\u4e92\u7684\u5f71\u54cd\uff0c\u8fdb\u800c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u77ed\u671f\u548c\u957f\u671f\u504f\u597d\u7684\u63a8\u8350\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u975e\u5e38\u6709\u6548\uff0c\u78e8\u9664\u7814\u7a76\u66f4\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u4e0d\u540c\u7c7b\u578b\u4e13\u5bb6\u7684\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u4e0d\u540c\u7684\u4e13\u4e1a\u63a8\u8350\u6a21\u578b\uff08\u4e13\u5bb6\uff09\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u52a8\u6001\u5730\u6574\u5408\u77ed\u671f\u548c\u957f\u671f\u504f\u597d\uff0c\u663e\u8457\u5730\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2506.23191", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.23191", "abs": "https://arxiv.org/abs/2506.23191", "authors": ["Gabriel Iturra-Bocaz", "Danny Vo", "Petra Galuscakova"], "title": "Impact of Shallow vs. Deep Relevance Judgments on BERT-based Reranking Models", "comment": "Accepted at ICTIR'25", "summary": "This paper investigates the impact of shallow versus deep relevance judgments\non the performance of BERT-based reranking models in neural Information\nRetrieval. Shallow-judged datasets, characterized by numerous queries each with\nfew relevance judgments, and deep-judged datasets, involving fewer queries with\nextensive relevance judgments, are compared. The research assesses how these\ndatasets affect the performance of BERT-based reranking models trained on them.\nThe experiments are run on the MS MARCO and LongEval collections. Results\nindicate that shallow-judged datasets generally enhance generalization and\neffectiveness of reranking models due to a broader range of available contexts.\nThe disadvantage of the deep-judged datasets might be mitigated by a larger\nnumber of negative training examples.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u6d45\u5c42\u548c\u6df1\u5c42\u76f8\u5173\u6027\u5224\u65ad\u5bf9BERT\u6a21\u578b\u5728\u795e\u7ecf\u4fe1\u606f\u68c0\u7d22\u4e2d\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u8868\u660e\u6d45\u5c42\u6570\u636e\u96c6\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\uff0c\u800c\u6df1\u5c42\u6570\u636e\u96c6\u53ef\u901a\u8fc7\u589e\u52a0\u8d1f\u8bad\u7ec3\u6837\u672c\u51cf\u8f7b\u5176\u52a3\u52bf\u3002", "motivation": "\u968f\u7740\u795e\u7ecf\u4fe1\u606f\u68c0\u7d22\u7684\u53d1\u5c55\uff0c\u7814\u7a76\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u96c6\u5bf9BERT\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u663e\u5f97\u5c24\u4e3a\u91cd\u8981\uff0c\u672c\u8bba\u6587\u65e8\u5728\u6bd4\u8f83\u6d45\u5c42\u548c\u6df1\u5c42\u5224\u65ad\u6570\u636e\u96c6\u5728\u6a21\u578b reranking \u6027\u80fd\u4e0a\u7684\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u5728MS MARCO\u548cLongEval\u6570\u636e\u96c6\u4e0a\u8fd0\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4f7f\u7528\u6d45\u5c42\u548c\u6df1\u5c42\u5224\u65ad\u6570\u636e\u96c6\u8bad\u7ec3\u7684BERT\u6a21\u578b\u5728re-ranking\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6d45\u5c42\u6570\u636e\u96c6\u901a\u5e38\u63d0\u9ad8reranking\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6548\u7387\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5b83\u4eec\u63d0\u4f9b\u4e86\u66f4\u591a\u7684\u4e0a\u4e0b\u6587\u8303\u56f4\u3002\u6df1\u5c42\u6570\u636e\u96c6\u7684\u7f3a\u9677\u53ef\u4ee5\u901a\u8fc7\u589e\u52a0\u8d1f\u8bad\u7ec3\u6837\u672c\u7684\u6570\u91cf\u6765\u5f25\u8865\u3002", "conclusion": "\u6d45\u5c42\u548c\u6df1\u5c42\u5224\u65ad\u6570\u636e\u96c6\u5bf9BERT\u6a21\u578b\u6027\u80fd\u6709\u4e0d\u540c\u5f71\u54cd\uff0c\u5e94\u6839\u636e\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u6570\u636e\u96c6\u3002\u589e\u52a0\u8d1f\u4f8b\u8bad\u7ec3\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6df1\u5c42\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.23319", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23319", "abs": "https://arxiv.org/abs/2506.23319", "authors": ["Norman Knyazev", "Harrie Oosterhuis"], "title": "Learning to Rank with Variable Result Presentation Lengths", "comment": "SIGIR 2025", "summary": "Learning to Rank (LTR) methods generally assume that each document in a top-K\nranking is presented in an equal format. However, previous work has shown that\nusers' perceptions of relevance can be changed by varying presentations, i.e.,\nallocating more vertical space to some documents to provide additional textual\nor image information. Furthermore, presentation length can also redirect\nattention, as users are more likely to notice longer presentations when\nscrolling through results. Deciding on the document presentation lengths in a\nfixed vertical space ranking is an important problem that has not been\naddressed by existing LTR methods.\n  We address this gap by introducing the variable presentation length ranking\ntask, where simultaneously the ordering of documents and their presentation\nlength is decided. Despite being a generalization of standard ranking, we show\nthat this setting brings significant new challenges: Firstly, the probability\nranking principle no longer applies to this setting, and secondly, the problem\ncannot be divided into separate ordering and length selection tasks.\n  We therefore propose VLPL - a new family of Plackett-Luce list-wise gradient\nestimation methods for the joint optimization of document ordering and lengths.\nOur semi-synthetic experiments show that VLPL can effectively balance the\nexpected exposure and attractiveness of all documents, achieving the best\nperformance across different ranking settings. Furthermore, we observe that\neven simple length-aware methods can achieve significant performance\nimprovements over fixed-length models. Altogether, our theoretical and\nempirical results highlight the importance and difficulties of combining\ndocument presentation with LTR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53d8\u91cf\u5448\u73b0\u957f\u5ea6\u6392\u540d\u4efb\u52a1\uff0c\u5e76\u8bbe\u8ba1\u4e86VLPL\u65b9\u6cd5\u6765\u8054\u5408\u4f18\u5316\u6587\u6863\u6392\u5e8f\u548c\u957f\u5ea6\uff0c\u5c55\u793a\u4e86\u76f8\u5bf9\u4e8e\u56fa\u5b9a\u957f\u5ea6\u6a21\u578b\uff0c\u5bf9\u6587\u6863\u7684\u9884\u671f\u66dd\u5149\u5ea6\u548c\u5438\u5f15\u529b\u8fdb\u884c\u6709\u6548\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u6392\u5e8f\u65b9\u6cd5\u5047\u8bbe\u6bcf\u4e2a\u6587\u6863\u7684\u5448\u73b0\u683c\u5f0f\u76f8\u540c\uff0c\u4f46\u7528\u6237\u5bf9\u76f8\u5173\u6027\u7684\u611f\u77e5\u53d7\u6587\u6863\u5448\u73b0\u957f\u5ea6\u5f71\u54cd\u3002\u672c\u6587\u9488\u5bf9\u672a\u89e3\u51b3\u7684\u6587\u6863\u5448\u73b0\u957f\u5ea6\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u7684\u6392\u540d\u4efb\u52a1\u3002", "method": "\u63d0\u51faVLPL\u65b9\u6cd5\uff0c\u901a\u8fc7Plackett-Luce\u5217\u8868\u68af\u5ea6\u4f30\u8ba1\u8fdb\u884c\u6587\u6863\u6392\u5e8f\u548c\u957f\u5ea6\u7684\u8054\u5408\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVLPL\u80fd\u6709\u6548\u5e73\u8861\u6587\u6863\u7684\u9884\u671f\u66dd\u5149\u5ea6\u548c\u5438\u5f15\u529b\uff0c\u5728\u591a\u79cd\u6392\u540d\u8bbe\u7f6e\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u7b80\u5355\u957f\u5ea6\u611f\u77e5\u65b9\u6cd5\u76f8\u6bd4\u56fa\u5b9a\u957f\u5ea6\u6a21\u578b\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u5f3a\u8c03\u4e86\u7ed3\u5408\u6587\u6863\u5448\u73b0\u4e0eLTR\u7684\u91cd\u8981\u6027\u53ca\u96be\u5ea6\u3002"}}
{"id": "2506.23394", "categories": ["cs.IR", "cs.AI", "cs.CL", "I.2.7; I.2.1"], "pdf": "https://arxiv.org/pdf/2506.23394", "abs": "https://arxiv.org/abs/2506.23394", "authors": ["Simeon Emanuilov"], "title": "Teaching a Language Model to Speak the Language of Tools", "comment": null, "summary": "External tool integration through function-calling is essential for practical\nlanguage model applications, yet most multilingual models lack reliable\ntool-use capabilities in non-English languages. Even state-of-the-art\nmultilingual models struggle with determining when to use tools and generating\nthe structured outputs required for function calls, often exhibiting language\nconfusion when prompted in lower-resource languages. This work presents a\nmethodology for adapting existing language models to enable robust tool use in\nany target language, using Bulgarian as a case study. The approach involves\ncontinued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a\nnovel bilingual dataset of 10,035 function-calling examples designed to support\nstandardized protocols like MCP (Model Context Protocol). The research\nintroduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to\n28.75% improvement in function-calling accuracy over base models while\npreserving core language understanding, as verified on established Bulgarian\nbenchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready\nresponse formatting with clean, parsable function calls, contrasting with the\nverbose and inconsistent outputs of base models. The models, evaluation\nframework, and dataset are released to enable replication for other languages.\nThis work demonstrates a practical approach for extending tool-augmented\ncapabilities beyond English-centric systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u53ef\u901a\u8fc7\u53cc\u8bed\u6570\u636e\u96c6\u8bad\u7ec3\u591a\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e2d\u53ef\u9760\u5730\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u591a\u8bed\u8a00\u6a21\u578b\u5728\u975e\u82f1\u8bed\u56fd\u5bb6\u7f3a\u4e4f\u53ef\u9760\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u96be\u4ee5\u786e\u5b9a\u4f55\u65f6\u4f7f\u7528\u5de5\u5177\u6216\u751f\u6210\u5fc5\u8981\u7684\u7ed3\u6784\u5316\u8f93\u51fa\u3002", "method": "\u7814\u7a76\u8005\u5bf9BgGPT\u6a21\u578b\u7cfb\u5217\u8fdb\u884c\u6301\u7eed\u8bad\u7ec3\uff0c\u4f7f\u7528\u4e86\u542b\u670910,035\u4e2a\u51fd\u6570\u8c03\u7528\u793a\u4f8b\u7684\u65b0\u578b\u53cc\u8bed\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u793a\u4f8b\u652f\u6301\u6807\u51c6\u5316\u7684MCP\u534f\u8bae\u3002", "result": "\u65b0\u6a21\u578bTUCAN\u5728\u4fdd\u4f4f\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e8628.75%\u7684\u51fd\u6570\u8c03\u7528\u51c6\u786e\u5ea6\u63d0\u5347\uff0c\u4e14\u80fd\u751f\u6210\u5e72\u51c0\u3001\u53ef\u89e3\u6790\u7684\u51fd\u6570\u8c03\u7528\u8f93\u51fa\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u5de5\u5177\u589e\u5f3a\u7684\u8bed\u8a00\u6a21\u578b\u529f\u80fd\u6446\u8131\u82f1\u8bed\u4e2d\u5fc3\u5316\uff0c\u4e3a\u5176\u4ed6\u8bed\u8a00\u4e5f\u63d0\u4f9b\u4e86\u65b0\u7684\u6a21\u578b\u3001\u8bc4\u4f30\u6846\u67b6\u548c\u6570\u636e\u96c6\uff0c\u4ee5\u4f9b\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u548c\u590d\u73b0\u3002"}}
{"id": "2506.23397", "categories": ["cs.IR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.23397", "abs": "https://arxiv.org/abs/2506.23397", "authors": ["Gaurav Sehgal", "Semih Salihoglu"], "title": "NaviX: A Native Vector Index Design for Graph DBMSs With Robust Predicate-Agnostic Search Performance", "comment": null, "summary": "There is an increasing demand for extending existing DBMSs with vector\nindices so that they become unified systems capable of supporting modern\npredictive applications, which require joint querying of vector embeddings\ntogether with the structured properties and connections of objects. We present\nNaviX, a native vector index for graph DBMSs (GDBMSs) that has two main design\ngoals. First, we aim to implement a disk-based vector index that leverages the\ncore storage and query-processing capabilities of the underlying GDBMS. To this\nend, NaviX is built on the Hierarchical Navigable Small-World (HNSW) graph,\nwhich itself is a graph-based structure. Second, we aim to support\npredicate-agnostic filtered vector search queries, in which the k nearest\nneighbors (kNNs) of a query vector vQ are searched only within an arbitrary\nsubset S of vectors defined by an ad-hoc selection sub-query QS. We adopt a\nprefiltering approach that evaluates QS first and passes the full description\nof subset S to the kNN search operator. We study how to design a prefiltering\nsearch algorithm that remains robust under varying selectivities and under\ndifferent correlations between subset S and query vector vQ. We propose an\nadaptive algorithm that uses the local selectivity of each vector in the HNSW\ngraph to choose an appropriate heuristic at every iteration of the kNN search.\nFinally, We demonstrate NaviX's robustness and efficiency through extensive\nexperiments against both existing prefiltering- and postfiltering-based\nbaselines.", "AI": {"tldr": "NaviX\u662f\u4e00\u4e2a\u4e3a\u56fe\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08GDBMSs\uff09\u8bbe\u8ba1\u7684\u539f\u751f\u5411\u91cf\u7d22\u5f15\uff0c\u652f\u6301\u5728\u7ed3\u6784\u5316\u548c\u8fde\u63a5\u5c5e\u6027\u4e2d\u67e5\u8be2\u5411\u91cf\u5d4c\u5165\uff0c\u5e76\u91c7\u7528\u9884\u5904\u7406\u8fc7\u6ee4\u65b9\u6cd5\u5b9e\u73b0\u9ad8\u6548\u7684\u5411\u91cf\u641c\u7d22\u3002", "motivation": "\u7531\u4e8e\u9884\u6d4b\u5e94\u7528\u7684\u9700\u8981\uff0c\u6269\u5c55\u73b0\u6709\u7684\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u4ee5\u652f\u6301\u5411\u91cf\u7d22\u5f15\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\u3002\u9700\u8981\u8054\u5408\u67e5\u8be2\u5411\u91cf\u5d4c\u5165\u53ca\u5176\u5bf9\u8c61\u7684\u5c5e\u6027\u548c\u8fde\u63a5\u5173\u7cfb\u3002", "method": "NaviX\u662f\u57fa\u4e8e\u5c42\u6b21\u5bfc\u822a\u5c0f\u4e16\u754c\uff08HNSW\uff09\u56fe\u6784\u5efa\u7684\u78c1\u76d8\u5411\u91cf\u7d22\u5f15\uff0c\u7ed3\u5408\u4e86\u4e0b\u5c42GDBMS\u7684\u6838\u5fc3\u5b58\u50a8\u548c\u67e5\u8be2\u5904\u7406\u80fd\u529b\u3002\u53e6\u5916\uff0cNaviX\u652f\u6301\u9884\u8fc7\u6ee4\u7684k\u6700\u8fd1\u90bb\uff08kNN\uff09\u641c\u7d22\uff0c\u901a\u8fc7\u5148\u8bc4\u4f30\u67e5\u8be2\u5b50\u67e5\u8be2QS\u5b9a\u4e49\u7684\u5411\u91cf\u5b50\u96c6S\uff0c\u7136\u540e\u5c06\u5b8c\u6574\u63cf\u8ff0\u4f20\u9012\u7ed9kNN\u641c\u7d22\u64cd\u4f5c\u7b26\u3002", "result": "NaviX\u901a\u8fc7\u81ea\u9002\u5e94\u7b97\u6cd5\u6839\u636eHNSW\u56fe\u4e2d\u6bcf\u4e2a\u5411\u91cf\u7684\u5c40\u90e8\u9009\u62e9\u6027\u6765\u9009\u62e9\u5408\u9002\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u589e\u5f3a\u4e86\u5728\u4e0d\u540c\u9009\u62e9\u6027\u548c\u4e0d\u540c\u76f8\u5173\u6027\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\uff0cNaviX\u5728\u62b5\u6297\u9884\u5904\u7406\u548c\u540e\u5904\u7406\u57fa\u7ebf\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.23471", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23471", "abs": "https://arxiv.org/abs/2506.23471", "authors": ["Thanh-Tung Phan-Nguyen", "Khoi-Nguyen Nguyen-Ngoc", "Tam V. Nguyen", "Minh-Triet Tran", "Trung-Nghia Le"], "title": "KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On", "comment": null, "summary": "The global fashion e-commerce industry has become integral to people's daily\nlives, leveraging technological advancements to offer personalized shopping\nexperiences, primarily through recommendation systems that enhance customer\nengagement through personalized suggestions. To improve customers' experience\nin online shopping, we propose a novel comprehensive KiseKloset system for\noutfit retrieval, recommendation, and try-on. We explore two approaches for\noutfit retrieval: similar item retrieval and text feedback-guided item\nretrieval. Notably, we introduce a novel transformer architecture designed to\nrecommend complementary items from diverse categories. Furthermore, we enhance\nthe overall performance of the search pipeline by integrating approximate\nalgorithms to optimize the search process. Additionally, addressing the crucial\nneeds of online shoppers, we employ a lightweight yet efficient virtual try-on\nframework capable of real-time operation, memory efficiency, and maintaining\nrealistic outputs compared to its predecessors. This virtual try-on module\nempowers users to visualize specific garments on themselves, enhancing the\ncustomers' experience and reducing costs associated with damaged items for\nretailers. We deployed our end-to-end system for online users to test and\nprovide feedback, enabling us to measure their satisfaction levels. The results\nof our user study revealed that 84% of participants found our comprehensive\nsystem highly useful, significantly improving their online shopping experience.", "AI": {"tldr": "\u8fd9\u4efd\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a KiseKloset \u7684\u7efc\u5408\u7cfb\u7edf\uff0c\u7528\u4e8e\u670d\u88c5\u7684\u68c0\u7d22\u3001\u63a8\u8350\u548c\u8bd5\u7a7f\uff0c\u5305\u62ec\u76f8\u4f3c\u9879\u76ee\u68c0\u7d22\u3001\u6587\u672c\u53cd\u9988\u6307\u5bfc\u9879\u76ee\u68c0\u7d22\u548c\u4e00\u79cd\u65b0\u7684 transformer \u67b6\u6784\u6765\u63a8\u8350\u4e92\u8865\u7269\u54c1\uff0c\u5e76\u7ed3\u5408\u4e86\u8f7b\u91cf\u7ea7\u7684\u865a\u62df\u8bd5\u7a7f\u6846\u67b6\uff0c\u7ed3\u679c\u663e\u793a\u7528\u6237\u6ee1\u610f\u5ea6\u5f88\u9ad8\u3002", "motivation": "\u63d0\u5347\u5728\u7ebf\u8d2d\u7269\u4f53\u9a8c\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e2a\u6027\u5316\u63a8\u8350\u7684\u8d2d\u7269\u65b9\u5f0f\u3002", "method": "\u521b\u4f5c\u4e86\u4e00\u4e2a\u540d\u4e3a KiseKloset \u7684\u7cfb\u7edf\uff0c\u6d89\u53ca\u670d\u88c5\u68c0\u7d22\u3001\u63a8\u8350\u548c\u8bd5\u7a7f\u6280\u672f\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u76f8\u4f3c\u9879\u76ee\u68c0\u7d22\u3001\u6587\u672c\u53cd\u9988\u6307\u5bfc\u9879\u76ee\u68c0\u7d22\u3001\u65b0\u7684 transformer \u67b6\u6784\u548c\u8f7b\u91cf\u7ea7\u7684\u865a\u62df\u8bd5\u7a7f\u6846\u67b6\u3002", "result": "\u7528\u6237\u7814\u7a76\u663e\u793a\uff0c84%\u7684\u53c2\u4e0e\u8005\u8ba4\u4e3a\u8be5\u7cfb\u7edf\u975e\u5e38\u6709\u7528\uff0c\u5927\u5927\u63d0\u5347\u4e86\u4ed6\u4eec\u7684\u5728\u7ebf\u8d2d\u7269\u4f53\u9a8c\u3002", "conclusion": "KiseKloset \u7cfb\u7edf\u901a\u8fc7\u521b\u65b0\u7684\u7b56\u7565\u548c\u5148\u8fdb\u7684\u6280\u672f\u663e\u8457\u63d0\u9ad8\u4e86\u6d88\u8d39\u8005\u7684\u5728\u7ebf\u8d2d\u7269\u4f53\u9a8c\uff0c\u5c55\u73b0\u4e86\u6781\u5927\u6f5c\u529b\u6539\u53d8\u5168\u7403\u65f6\u5c1a\u7535\u5b50\u5546\u52a1\u4ea7\u4e1a\u7684\u9762\u8c8c\u3002"}}
{"id": "2506.23643", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.23643", "abs": "https://arxiv.org/abs/2506.23643", "authors": ["Yifan Wang", "Weinan Gan", "Longtao Xiao", "Jieming Zhu", "Heng Chang", "Haozhao Wang", "Rui Zhang", "Zhenhua Dong", "Ruiming Tang", "Ruixuan Li"], "title": "Act-With-Think: Chunk Auto-Regressive Modeling for Generative Recommendation", "comment": "9 pages, 2 figures", "summary": "Generative recommendation (GR) typically encodes behavioral or semantic\naspects of item information into discrete tokens, leveraging the standard\nautoregressive (AR) generation paradigm to make predictions. However, existing\nmethods tend to overlook their intrinsic relationship, that is, the semantic\nusually provides some reasonable explainability \"$\\textbf{why}$\" for the\nbehavior \"$\\textbf{what}$\", which may constrain the full potential of GR. To\nthis end, we present Chunk AutoRegressive Modeling (CAR), a new generation\nparadigm following the decision pattern that users usually think semantic\naspects of items (e.g. brand) and then take actions on target items (e.g.\npurchase). Our CAR, for the $\\textit{first time}$, incorporates semantics\n(SIDs) and behavior (UID) into a single autoregressive transformer from an\n``act-with-think'' dual perspective via chunk-level autoregression.\nSpecifically, CAR packs SIDs and UID into a conceptual chunk for item unified\nrepresentation, allowing each decoding step to make a holistic prediction.\nExperiments show that our CAR significantly outperforms existing methods based\non traditional AR, improving Recall@5 by 7.93% to 22.30%. Furthermore, we\nverify the scaling effect between model performance and SIDs bit number,\ndemonstrating that CAR preliminary emulates a kind of slow-thinking style\nmechanism akin to the reasoning processes observed in large language models\n(LLMs).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Chunk AutoRegressive Modeling (CAR)\uff0c\u4e00\u79cd\u901a\u8fc7\u7ed3\u5408\u5185\u5bb9\u548c\u884c\u4e3a\u4fe1\u606f\u4ee5\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u4e86\u5185\u5bb9\u548c\u884c\u4e3a\u4fe1\u606f\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u3002", "method": "CAR\u65b9\u6cd5\u901a\u8fc7\u5c06\u5185\u5bb9\u7684\u8bed\u4e49\u4fe1\u606f\uff08SIDs\uff09\u548c\u7528\u6237\u884c\u4e3a\uff08UID\uff09\u6574\u5408\u5230\u4e00\u4e2a\u81ea\u56de\u5f52Transformer\u6a21\u578b\u4e2d\uff0c\u4ece\u201c\u884c\u52a8-\u601d\u8003\u201d\u7684\u53cc\u91cd\u89c6\u89d2\u8fdb\u884c\u63a8\u8350\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4f20\u7edf\u81ea\u56de\u5f52\u65b9\u6cd5\u7684\u57fa\u7840\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0cRecall@5\u4ece7.93%\u63d0\u9ad8\u523022.30%\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6a21\u578b\u6027\u80fd\u4e0eSIDs\u4f4d\u6570\u6b63\u76f8\u5173\u3002", "conclusion": "CAR\u521d\u6b65\u6a21\u4eff\u4e86\u7c7b\u4f3c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u65b9\u6cd5\u3002"}}
